{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #2: Language models\n",
    "### Author: Hicham Mohamad (hi8826mo-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Table of Contents\n",
    " ==\n",
    "1. [Collecting and analyzing a corpus](#t1)\n",
    "2. [Segmenting a corpus](#t2)\n",
    "3. [Counting unigrams and bigrams](#t3)\n",
    "4. [Computing the likelihood of a sentence](#t4)\n",
    "5. [Online prediction of words](#t5)\n",
    "6. [Check answers](#t6)\n",
    "7. [Submission](#t7)\n",
    "8. [Reading](#t8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objectives of this assignment are to:\n",
    "* Write a program to find n-gram statistics\n",
    "* Compute the probability of a sentence\n",
    "* Know what a language model is\n",
    "* Write a short report of 1 to 2 pages on the assignment\n",
    "* Optionally read a short article on the importance of corpora\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have written all the missing code and run all the cells, you will submit your notebook to an automatic marking system. Do not erase the content of the cells as we will possibly check your programs manually.\n",
    "The submission instructions are at the bottom of the notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Each group will have to write Python programs to count **unigrams**, **bigrams**, and **trigrams** in a corpus of approximately one million words and to determine the probability of a sentence.\n",
    "* You can test you regular expression using the **regex101.com** site\n",
    "* Each student will have to write a short report of one to two pages and comment briefly the results. In your report, you must produce the tabulated results of your analysis as described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some imports you may need. Add others as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import math\n",
    "import os\n",
    "import regex as re\n",
    "import requests\n",
    "import sys\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting and analyzing a corpus <a name=\"t1\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may have to adjust the path\n",
    "#corpus = open('../../../corpus/Selma.txt', encoding='utf8').read()\n",
    "corpus = open('Selma.txt', encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run the <a href=\"https://github.com/pnugues/ilppp/tree/master/programs/ch02/python\">concordance\n",
    "program </a> to print the lines containing a specific word, for instance <i>Nils</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = 'Nils Holgersson'\n",
    "width = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concordance program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selma Lagerlöf Nils Holgerssons underbara resa genom Sv\n",
      "! Se på Tummetott! Se på Nils Holgersson Tummetott!» Genast vände\n",
      "r,» sade han. »Jag heter Nils Holgersson och är son till en husma\n",
      "lden. »Inte är det värt, Nils Holgersson, att du är ängslig eller\n",
      " i dem. På den tiden, då Nils Holgersson drog omkring med vildgäs\n",
      "ulle allt visa honom vad Nils Holgersson från Västra Vemmenhög va\n",
      "om ägde rum det året, då Nils Holgersson for omkring med vildgäss\n",
      "m vad det kan kosta dem. Nils Holgersson hade inte haft förstånd \n",
      "de det inte mer sägas om Nils Holgersson, att han inte tyckte om \n",
      " Rosenbom?» För där stod Nils Holgersson mitt uppe på Rosenboms n\n",
      " Med ens fingo de syn på Nils Holgersson, och då sköt den store v\n",
      "vila. När vildgässen och Nils Holgersson äntligen hade letat sig \n",
      " slags arbetare. Men vad Nils Holgersson inte såg, det var, att s\n",
      "nde han fråga, och om då Nils Holgersson sade nej, började han ge\n",
      "de lille Mats, och om nu Nils Holgersson också hade tegat, så had\n",
      "åg så försmädlig ut, att Nils Holgersson kastade sig över honom f\n",
      " brodern. Och inte ville Nils Holgersson slåss med en tös, utan h\n",
      "örkar. På den tiden, när Nils Holgersson for omkring med vildgäss\n",
      " ryckte omkull honom. Om Nils Holgersson genast hade ropat på hjä\n",
      "u reda dig på egen hand, Nils Holgersson,» sade han då till sig s\n",
      "r satte Fumle-Drumle ner Nils Holgersson på bottnen av en sandgro\n",
      "mlingarna. – »Jo, jag är Nils Holgersson från Västra Vemmenhög, s\n",
      "rakten. På den tiden, då Nils Holgersson for omkring med vildgäss\n",
      "Jo, det står – Det står: Nils Holgersson fr. V. Vemmenhög.» »Det \n",
      "visan 1 Sveriges karta 2 Nils Holgerssons underbara resa genom Sv\n",
      "admalsvåden 233 ________ Nils Holgerssons underbara resa genom Sv\n",
      "R. Tolv år ungefär innan Nils Holgersson hade börjat resa omkring\n",
      "och leta efter föda, men Nils Holgersson hade på morgonen tappat \n",
      "ill i Närke det året, då Nils Holgersson for fram över landskapet\n",
      "hade flyttat tassen över Nils Holgerssons ansikte, så att den sta\n",
      "29 april. Denna dag fick Nils Holgersson se södra Dalarna. Vildgä\n",
      "rliga sjön. Det året, då Nils Holgersson for med vildgässen genom\n",
      "t skänka upptäckten till Nils Holgersson. Det var ju både det tro\n",
      " som sången varade, stod Nils Holgersson och lyssnade till den, m\n",
      "ova på en vassrugge. Vad Nils Holgersson angår, så var han för hu\n",
      "e svårt för en sådan som Nils Holgersson att finna en farkost. Ha\n",
      "r de hade kommit mittför Nils Holgersson, slogo de sig ner på ett\n",
      " 5 maj. På den tiden, då Nils Holgersson drog genom landet med vi\n",
      "an vara bra lycklig. Att Nils Holgersson, som för ett par timmar \n",
      " afton. Och således hade Nils Holgersson fått se studenterna, när\n",
      "nger under marschen. Men Nils Holgersson hade tyckt, att det inte\n",
      "och glädja så som dessa. Nils Holgersson hade mest sett på studen\n",
      "m, stannade han. »Jag är Nils Holgersson från Västra Vemmenhög,» \n",
      " Ett par år före det, då Nils Holgersson drog omkring med vildgäs\n",
      " detsamma fattade han om Nils Holgersson med sin stora fot, höjde\n",
      "t ingen mer än den lilla Nils Holgersson, som följde henne. Solen\n",
      " voro klädda med is, och Nils Holgersson ville följa henne dit in\n",
      "t Lappland är mitt!» Men Nils Holgersson hade blivit så ängslig, \n",
      " över klippväggarna, och Nils Holgersson kunde förstå, att det va\n",
      " SJUKDOMEN. Det året, då Nils Holgersson for omkring med vildgäss\n",
      "jligt att undgå den. Vad Nils Holgersson beträffar, så hade han h\n",
      "hade hon slagit klorna i Nils Holgerssons skuldra och hackade eft\n",
      "g, att just det året, då Nils Holgersson for omkring med vildgäss\n",
      " lönt att vara bedrövad, Nils Holgersson,» sade solen. »Världen ä\n",
      "åga om han inte kunde ge Nils Holgersson bättre villkor. ’Det öns\n",
      "du vill,’ sade han. ’Med Nils Holgersson blir det ändå så, som ja\n",
      "a haft av honom. Ja, säg Nils Holgersson, att föräldrarna redan h\n",
      "Västergötland. Den lille Nils Holgersson hade krupit upp på en la\n",
      " honom sämre.» Den lille Nils Holgersson hade följt med barnen he\n",
      "e bara störa.» Då tyckte Nils Holgersson, att när ingen annan gjo\n",
      "n färdig att följa det.» Nils Holgersson sprang raskt neråt vägen\n",
      "rott mellan de unga. Vad Nils Holgersson beträffar, så hade han i\n",
      "on gav sig tid att se på Nils Holgersson, innan hon stötte till. \n",
      " ändå alldeles olik. Den Nils Holgersson, som hade farit bort i v\n",
      " tro det. Välkommen hem, Nils Holgersson, välkommen hem! Det här \n",
      "mig här på gården,» sade Nils Holgersson. »Min egen mor tror, att\n",
      "on riktig sjukdom,» sade Nils Holgersson. »Jag får försöka ställa\n",
      "in kniv här på din hov?» Nils Holgersson var nätt och jämnt färdi\n",
      "sslingen, som var så lik Nils Holgersson, att om det inte var han\n",
      "pojken fanns i närheten. Nils Holgersson hörde honom nog, men han\n",
      "ottrar ihop ett tack för Nils Holgersson? Vad skulle det ha blivi\n"
     ]
    }
   ],
   "source": [
    "# spaces match tabs and newlines\n",
    "pattern = re.sub(' ', '\\\\s+', pattern)\n",
    "# Replaces newlines with spaces in the text\n",
    "clean_corpus = re.sub('\\s+', ' ', corpus)\n",
    "concordance = ('(.{{0,{width}}}{pattern}.{{0,{width}}})'\n",
    "               .format(pattern=pattern, width=width))\n",
    "for match in re.finditer(concordance, clean_corpus):\n",
    "    print(match.group(1))\n",
    "# print the string with 0..width characters on either side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run a simple <a href=\"https://github.com/pnugues/ilppp/tree/master/programs/ch05/python\">tokenization\n",
    "program</a> on your corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    words = re.findall('\\p{L}+', text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Selma',\n",
       " 'Lagerlöf',\n",
       " 'Nils',\n",
       " 'Holgerssons',\n",
       " 'underbara',\n",
       " 'resa',\n",
       " 'genom',\n",
       " 'Sverige',\n",
       " 'Första',\n",
       " 'bandet']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = tokenize(corpus)\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Count the number of **unique words** in the original corpus and then setting all the words in **lowercase**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "# Count the words and store them in a dictionary.\n",
    "# It scans the words list and \n",
    "# increments the frequency of the words as they occur.\n",
    "def count_unigrams(words):\n",
    "    frequency = {}\n",
    "    for word in words:\n",
    "        if word in frequency:\n",
    "            frequency[word] += 1\n",
    "        else:\n",
    "            frequency[word] = 1\n",
    "            \n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary/words:  923485\n",
      "unique words:  44256\n"
     ]
    }
   ],
   "source": [
    "frequency = count_unigrams(words)\n",
    "print('vocabulary/words: ', len(words))\n",
    "print('unique words: ', len(frequency))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lowercased text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['selma',\n",
       " 'lagerlöf',\n",
       " 'nils',\n",
       " 'holgerssons',\n",
       " 'underbara',\n",
       " 'resa',\n",
       " 'genom',\n",
       " 'sverige',\n",
       " 'första',\n",
       " 'bandet']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "lowerwords = []\n",
    "for word in words:\n",
    "    lowerwords.append(word.lower())\n",
    "    \n",
    "#print(len(lowerwords))    \n",
    "lowerwords[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmenting a corpus <a name=\"t2\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will write a program to tokenize your text, insert `<s>` and `</s>` tags to delimit sentences, and set all the words in lowercase letters. In the end, you will only keep the words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalizing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a **regular expression** that matches all the characters that are neither a letter nor a punctuation sign. The **punctuations signs** will be the followings: `.;:?!`. In your regex, use the same order. For the definition of a letter, use a Unicode regex. You will call the regex string `nonletter`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** A string of characters enclosed in square **brackets** ([ ]) matches any one character in that string. If the first character in the brackets is a **caret** (^), it matches any character except those in the string. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "nonletter = '([^\\p{L}.;:?!]+)'\n",
    "#re.findall(nonletter, 'En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a `clean()` function that replaces all the characters that are neither a letter nor a punctuation sign with a **space**. The punctuations signs will be the followings: `.;:?!`.   For the sentence:\n",
    "\n",
    "_En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa._\n",
    "\n",
    "the result will be:\n",
    "\n",
    "`En gång hade de på Mårbacka en barnpiga som hette Back Kajsa.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def clean(text):\n",
    "    return re.sub(nonletter, ' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En gång hade de på Mårbacka en barnpiga som hette Back Kajsa.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean('En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_para = 'En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa. \\\n",
    "Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, \\\n",
    "hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, \\\n",
    "när hon kammade dem, och till humöret var hon dyster och sorgbunden.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'En gång hade de på Mårbacka en barnpiga som hette Back Kajsa. Hon var nog sina tre alnar lång hon hade ett stort grovt ansikte med stränga mörka drag hennes händer voro hårda och fulla av sprickor som barnens hår fastnade i när hon kammade dem och till humöret var hon dyster och sorgbunden.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_para = clean(test_para)\n",
    "test_para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Segmenter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will write a **sentence segmenter** that will delimit each sentence with `</s>` and `<s>` symbols. For example the sentence:\n",
    "\n",
    "_En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa._\n",
    "\n",
    "will be bracketed as:\n",
    "\n",
    "`<s> En gång hade de på Mårbacka en barnpiga som hette Back-Kajsa </s>`\n",
    "\n",
    "As algorithm, you will use a simple heuristics to detect the **sentence boundaries**: *A sentence starts with a capital letter and ends with a period-equivalent punctuation sign*. You will write a **regex** to match these boundaries with a regular expression and you will insert `</s>\\n<s>` symbols with a **substitution** function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Detecting sentence boundaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a **regular expression** that matches a punctuation, a sequence of spaces, and an uppercase letter. Call this regex string `sentence_boundaries`. In the regex, you will remember the value of the uppercase letter using a **backreference**. Use the **Unicode regexes** for the letters and the spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backreference examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text = \"From the beginning of the world. There was a ship. The man with no tail.\"\n",
    "\n",
    "def normalization(text):\n",
    "    return re.sub('([\\p{S}\\p{P}])', r' \\1 ', text)\n",
    "\n",
    "normalization(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re.sub(r'(\\b[a-z]+) \\1', r'\\1', 'cat in the the hat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The '`r`' at the start of the pattern string designates a **python \"raw\" string** which passes through backslashes without change.\n",
    "- Square brackets can be used to indicate a **set of chars**, so `[abc]` matches 'a' or 'b' or 'c'. \n",
    "- It is often useful to be able to refer to a particular subpart of the string matching the first pattern. For example, suppose we wanted to put angle brackets around all integers in a text, changing e.g. the *the 35 boxes* to *the <35> boxes*. We'd like a way to *refer back* to the integer we've found so that we can easily add the brackets. To do this, we put *parenthese* `(` and `)`around the first pattern, and use the **number operator** `\\1` in the second pattern to refer back. Here is how it looks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re.sub(r'([0-9]+) \\1', r'<\\1>', 'the the 35 35 boxes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "re.sub(r'([a-z]+) \\1', r'\\1', 'the the 35 35 boxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "# \\p{Lu}  an uppercase letter that has a lowercase variant.\n",
    "# sentence_boundaries = r'\\p{P}\\s+(\\p{Lu})' \n",
    "sentence_boundaries = r'[.;:?!]+\\p{Z}+(\\p{Lu})'\n",
    "#sentence_boundaries = r'(\\p{Lu})'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Replacement markup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a regex string to replace the **matched boundaries** with the sentence **boundary markup**. Remember that a sentence ends with `</s>` and starts with `<s>` and that there is one sentence per line. Hint: The markup is `</s>\\n<s>`. Remember also that the first letter of your sentence is in a **regex backreference**. Call the regex string `sentence_markup`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "sentence_markup = r' </s>\\n<s> \\1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Applying the substitution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use your regexes to segment your text. Use the string `sentence_boundaries`, `sentence_markup`, and `test_para` as input and `text` as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "text = re.sub(sentence_boundaries, sentence_markup, test_para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En gång hade de på Mårbacka en barnpiga som hette Back Kajsa </s>\n",
      "<s> Hon var nog sina tre alnar lång hon hade ett stort grovt ansikte med stränga mörka drag hennes händer voro hårda och fulla av sprickor som barnens hår fastnade i när hon kammade dem och till humöret var hon dyster och sorgbunden.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like this:\n",
    "\n",
    "`En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa </s>\n",
    "<s> Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, när hon kammade dem, och till humöret var hon dyster och sorgbunden.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Insert **markup codes** in the beginning and end of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> En gång hade de på Mårbacka en barnpiga som hette Back Kajsa </s>\n",
      "<s> Hon var nog sina tre alnar lång hon hade ett stort grovt ansikte med stränga mörka drag hennes händer voro hårda och fulla av sprickor som barnens hår fastnade i när hon kammade dem och till humöret var hon dyster och sorgbunden. </s>\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "#text = re.sub(r'^', r' <s> ', text)\n",
    "#text = re.sub(r'$', r' </s>', text)\n",
    "text = '<s> ' + text + ' </s>'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like this:\n",
    "\n",
    "`<s> En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa </s>\n",
    "<s> Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, när hon kammade dem, och till humöret var hon dyster och sorgbunden. </s>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Replace the **space duplicates** with one space and remove the **punctuation signs**. For the spaces, use the Unicode regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "# Replace the space duplicates with one space\n",
    "# Z refers to seperators\n",
    "text = re.sub(r'\\p{Z}+', r' ', text)\n",
    "\n",
    "# remove the punctuation signs\n",
    "text = re.sub(r'[.;:?!]', r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> En gång hade de på Mårbacka en barnpiga som hette Back Kajsa </s>\n",
      "<s> Hon var nog sina tre alnar lång hon hade ett stort grovt ansikte med stränga mörka drag hennes händer voro hårda och fulla av sprickor som barnens hår fastnade i när hon kammade dem och till humöret var hon dyster och sorgbunden </s>\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output should look like this:\n",
    "    \n",
    "`<s> En gång hade de på Mårbacka en barnpiga, som hette Back-Kajsa </s>\n",
    "<s> Hon var nog sina tre alnar lång, hon hade ett stort, grovt ansikte med stränga, mörka drag, hennes händer voro hårda och fulla av sprickor, som barnens hår fastnade i, när hon kammade dem, och till humöret var hon dyster och sorgbunden </s>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a `segment_sentences(text)` function to gather the code in the **Segmenter** section and set the text in **lowercase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def segment_sentences(text):\n",
    "    # matches a punctuation, a sequence of spaces, and an uppercase letter\n",
    "    sentence_boundaries = r'[.;:?!]\\p{Z}+(\\p{Lu})'\n",
    "    \n",
    "    # sentence boundary markup\n",
    "    sentence_markup = r' </s>\\n<s> \\1'\n",
    "    \n",
    "    # Substitution: replace the matched boundaries with the sentence boundary markup\n",
    "    text = re.sub(sentence_boundaries, sentence_markup, text)\n",
    "    \n",
    "    # Insert markup codes in the beginning and end of the text\n",
    "    text = '<s> ' + text + ' </s>'\n",
    "    \n",
    "    # Replace the space duplicates with one space\n",
    "    # Z refers to seperators\n",
    "    text = re.sub(r'\\p{Z}+', r' ', text)\n",
    "    \n",
    "    # remove the punctuation signs\n",
    "    text = re.sub(r'[.;:?!]', r'', text)\n",
    "    #text = re.sub(r'^', r'<s> ', text)\n",
    "    #text = re.sub(r'$', r' </s>', text)\n",
    "        \n",
    "    text = text.lower()\n",
    "    return text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> en gång hade de på mårbacka en barnpiga som hette back kajsa </s>\n",
      "<s> hon var nog sina tre alnar lång hon hade ett stort grovt ansikte med stränga mörka drag hennes händer voro hårda och fulla av sprickor som barnens hår fastnade i när hon kammade dem och till humöret var hon dyster och sorgbunden </s>\n"
     ]
    }
   ],
   "source": [
    "print(segment_sentences(test_para))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Estimate roughly the **accuracy** of your program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean and segment the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "#corpus = open('Selma.txt', encoding='utf8').read()\n",
    "#print(corpus[-557:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = clean(corpus)\n",
    "corpus = segment_sentences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> hon hade fått större kärlek av sina föräldrar än någon annan han visste och sådan kärlek måste vändas i välsignelse </s>\n",
      "<s> då prästen sade detta kom alla människor att se bort mot klara gulla och de förundrade sig över vad de såg </s>\n",
      "<s> prästens ord tycktes redan ha gått i uppfyllelse </s>\n",
      "<s> där stod klara fina gulleborg ifrån skrolycka hon som var uppkallad efter själva solen vid sina föräldrars grav och lyste som en förklarad </s>\n",
      "<s> hon var likaså vacker som den söndagen då hon gick till kyrkan i den röda klänningen om inte vackrare </s>\n"
     ]
    }
   ],
   "source": [
    "print(corpus[-557:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result should be a **normalized text** without punctuation signs where all the sentences are delimited with `<s>` and `</s>` tags. The five last lines of the text should look like this:\n",
    "\n",
    "```\n",
    "<s> hon hade fått större kärlek av sina föräldrar än någon annan han visste och sådan kärlek måste vändas i välsignelse </s> \n",
    "<s> då prästen sade detta kom alla människor att se bort mot klara gulla och de förundrade sig över vad de såg </s>\n",
    "<s> prästens ord tycktes redan ha gått i uppfyllelse </s>\n",
    "<s> där stod klara fina gulleborg ifrån skrolycka hon som var uppkallad efter själva solen vid sina föräldrars grav och lyste som en förklarad </s>\n",
    "<s> hon var likaså vacker som den söndagen då hon gick till kyrkan i den röda klänningen om inte vackrare </s>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You will now create a **list of words** from your string. You will consider that a space or a carriage return is an item **separator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "wordsOnLine = re.sub(r'\\s+', r'\\n', corpus)\n",
    "#print(type(wordsOnLine))\n",
    "words = wordsOnLine.split()\n",
    "#words.remove('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'hon', 'hade', 'fått', 'större', 'kärlek', 'av', 'sina', 'föräldrar', 'än', 'någon', 'annan', 'han', 'visste', 'och', 'sådan', 'kärlek', 'måste', 'vändas', 'i', 'välsignelse', '</s>', '<s>', 'då', 'prästen', 'sade', 'detta', 'kom', 'alla', 'människor', 'att', 'se', 'bort', 'mot', 'klara', 'gulla', 'och', 'de', 'förundrade', 'sig', 'över', 'vad', 'de', 'såg', '</s>', '<s>', 'prästens', 'ord', 'tycktes', 'redan', 'ha', 'gått', 'i', 'uppfyllelse', '</s>', '<s>', 'där', 'stod', 'klara', 'fina', 'gulleborg', 'ifrån', 'skrolycka', 'hon', 'som', 'var', 'uppkallad', 'efter', 'själva', 'solen', 'vid', 'sina', 'föräldrars', 'grav', 'och', 'lyste', 'som', 'en', 'förklarad', '</s>', '<s>', 'hon', 'var', 'likaså', 'vacker', 'som', 'den', 'söndagen', 'då', 'hon', 'gick', 'till', 'kyrkan', 'i', 'den', 'röda', 'klänningen', 'om', 'inte', 'vackrare', '</s>']\n"
     ]
    }
   ],
   "source": [
    "print(words[-101:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The five last lines of the corpus should like this:\n",
    "\n",
    "`['<s>', 'hon', 'hade', 'fått', 'större', 'kärlek', 'av', 'sina', 'föräldrar', 'än', 'någon', 'annan', 'han', 'visste', 'och', 'sådan', 'kärlek', 'måste', 'vändas', 'i', 'välsignelse', '</s>', '<s>', 'då', 'prästen', 'sade', 'detta', 'kom', 'alla', 'människor', 'att', 'se', 'bort', 'mot', 'klara', 'gulla', 'och', 'de', 'förundrade', 'sig', 'över', 'vad', 'de', 'såg', '</s>', '<s>', 'prästens', 'ord', 'tycktes', 'redan', 'ha', 'gått', 'i', 'uppfyllelse', '</s>', '<s>', 'där', 'stod', 'klara', 'fina', 'gulleborg', 'ifrån', 'skrolycka', 'hon', 'som', 'var', 'uppkallad', 'efter', 'själva', 'solen', 'vid', 'sina', 'föräldrars', 'grav', 'och', 'lyste', 'som', 'en', 'förklarad', '</s>', '<s>', 'hon', 'var', 'likaså', 'vacker', 'som', 'den', 'söndagen', 'då', 'hon', 'gick', 'till', 'kyrkan', 'i', 'den', 'röda', 'klänningen', 'om', 'inte', 'vackrare', '</s>']`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting unigrams and bigrams <a name=\"t3\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and try programs to compute the **frequency** of unigrams and bigrams of the training set: [<a\n",
    "            href=\"https://github.com/pnugues/ilppp/tree/master/programs/ch05/python\">Program folder</a>]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: \n",
    "Knowing the frequency of words and sequences of words is crucial in many fields\n",
    "of language processing. \n",
    "- We first normalized the text: we created a file with one sentence per line. \n",
    "- We inserted automatically the delimiters `<s>` and `</s>`. \n",
    "- We removed the punctuations, parentheses, quotes, stars, dashes, tabulations and double white spaces. \n",
    "- We set all the words in lowercase letters. \n",
    "- We counted the word, and we produced a file with the unigram and bigram counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unigrams(words):\n",
    "    frequency = {}\n",
    "    for i in range(len(words)):\n",
    "        if words[i] in frequency:\n",
    "            frequency[words[i]] += 1\n",
    "        else:\n",
    "            frequency[words[i]] = 1\n",
    "    return frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 59047),\n",
       " ('selma', 52),\n",
       " ('lagerlöf', 270),\n",
       " ('nils', 87),\n",
       " ('holgerssons', 6),\n",
       " ('underbara', 23),\n",
       " ('resa', 317),\n",
       " ('genom', 688),\n",
       " ('sverige', 56),\n",
       " ('</s>', 59047),\n",
       " ('första', 525),\n",
       " ('bandet', 6),\n",
       " ('bokutgåva', 11),\n",
       " ('albert', 15),\n",
       " ('bonniers', 11),\n",
       " ('förlag', 11),\n",
       " ('stockholm', 77),\n",
       " ('den', 11624),\n",
       " ('kristliga', 2),\n",
       " ('dagvisan', 2)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency = unigrams(words)\n",
    "list(frequency.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bigrams(words):\n",
    "    bigrams = []\n",
    "    for i in range(len(words) - 1):\n",
    "        bigrams.append((words[i], words[i + 1]))\n",
    "    frequency_bigrams = {}\n",
    "    for i in range(len(words) - 1):\n",
    "        if bigrams[i] in frequency_bigrams:\n",
    "            frequency_bigrams[bigrams[i]] += 1\n",
    "        else:\n",
    "            frequency_bigrams[bigrams[i]] = 1\n",
    "    return frequency_bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('<s>', 'selma'), 8),\n",
       " (('selma', 'lagerlöf'), 11),\n",
       " (('lagerlöf', 'nils'), 1),\n",
       " (('nils', 'holgerssons'), 6),\n",
       " (('holgerssons', 'underbara'), 4),\n",
       " (('underbara', 'resa'), 4),\n",
       " (('resa', 'genom'), 6),\n",
       " (('genom', 'sverige'), 5),\n",
       " (('sverige', '</s>'), 17),\n",
       " (('</s>', '<s>'), 59046),\n",
       " (('<s>', 'första'), 11),\n",
       " (('första', 'bandet'), 1),\n",
       " (('bandet', 'bokutgåva'), 2),\n",
       " (('bokutgåva', 'albert'), 11),\n",
       " (('albert', 'bonniers'), 11),\n",
       " (('bonniers', 'förlag'), 11),\n",
       " (('förlag', 'stockholm'), 10),\n",
       " (('stockholm', '</s>'), 24),\n",
       " (('<s>', 'den'), 1375),\n",
       " (('den', 'kristliga'), 2)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_bigrams = bigrams(words)\n",
    "list(frequency_bigrams.items())[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the report, tell what is the **possible number** of bigrams and their **real numbe**r? Explain why such a difference. \n",
    "- What would be the possible number of 4-grams.\n",
    "- Propose a **solution** to cope with bigrams **unseen** in the corpus. This topic will be discussed during the lab session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bigram model approximates the probability of a word given all the previous words by using only the **conditional probability** of the preceding word. When we use a bigram model to predict the conditional probability of the next word, we are thus making the following approximation:\n",
    "\\begin{equation*}\n",
    "P(w_n|w_1^{n-1})  \\approx P(w_n|w_{n-1})\n",
    "\\end{equation*}\n",
    "we can compute the probability of a complete word sequence by\n",
    "\\begin{equation*}\n",
    "P(w_1^n)  \\approx \\prod_{k=1}^{n} P(w_k|w_{k-1})\n",
    "\\end{equation*}\n",
    "The assumption that the probability of a word depends only on the previous word is is called a **Markov** assumption. **Markov models** are the class of probabilistic models that assume we can predict the probability of some future unit without looking too far into the past. \n",
    "\n",
    "We can generalize the bigram (which looks one word into the past) to the trigram (which looks two words into the past) \n",
    "\\begin{equation*}\n",
    "P(w_n|w_1^{n-1})  \\approx P(w_n|w_{n-2}w_{n-1})\n",
    "\\end{equation*}\n",
    "and thus to the n-gram (which looks n−1 words into the past). For example, 4-gram models condition on the previous three words rather than the previous word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the likelihood of a sentence <a name=\"t4\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice we don’t use **raw probability** as our metric for evaluating language models, but a variant called **perplexity**. The perplexity (sometimes called PP for short) of a language model on a test set is the **inverse probability** of the test set, normalized by the number of words. For a test set $W = w_1 w_2 \\cdots w_N$, if we are computing the perplexity of $W$ with a bigram language model,\n",
    "we get:\n",
    "\\begin{equation*}\n",
    "PP(W) = \\sqrt[N]{\\prod_{i=1}^{N} \\frac{1}{P(w_i|w_{i-1})}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a program to compute a **sentence's probability** using unigrams. You may find useful the **dictionaries** that we saw in the **mutual information** program: [<a href=\"https://github.com/pnugues/ilppp/tree/master/programs/ch05/python\">Program folder</a>]. Your function will return the **perplexity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your function should **print and tabulate** the results as in the examples below with the sentence _Det var en gång en katt som hette Nils_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "=====================================================\n",
    "wi \t C(wi) \t #words \t P(wi)\n",
    "=====================================================\n",
    "det \t 21108 \t 1041631 \t 0.0202643738521607\n",
    "var \t 12090 \t 1041631 \t 0.01160679741674355\n",
    "en \t 13514 \t 1041631 \t 0.01297388422579589\n",
    "gång \t 1332 \t 1041631 \t 0.001278763784871994\n",
    "en \t 13514 \t 1041631 \t 0.01297388422579589\n",
    "katt \t 16 \t 1041631 \t 1.5360525944408337e-05\n",
    "som \t 16288 \t 1041631 \t 0.015637015411407686\n",
    "hette \t 97 \t 1041631 \t 9.312318853797554e-05\n",
    "nils \t 87 \t 1041631 \t 8.352285982272032e-05\n",
    "</s> \t 59047 \t 1041631 \t 0.056687060964967444\n",
    "=====================================================\n",
    "Prob. unigrams:\t 5.361459667285409e-27\n",
    "Geometric mean prob.: 0.0023600885848765307\n",
    "Entropy rate:\t 8.726943273141258\n",
    "Perplexity:\t 423.71290908655254\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def unigram_lm(freq_unigrams, sent_words):\n",
    "    print('=====================================================')\n",
    "    print('wi      C(wi)      #words      P(wi)')\n",
    "    print('=====================================================')\n",
    "    \n",
    "    #sentence = {}\n",
    "    # entropy\n",
    "    #entropy = 0\n",
    "    prob_unigrams = 1\n",
    "    # We need the end-symbol to make the bigram grammar a true probability \n",
    "    # distribution. Without an end-symbol, the sentence probabilities \n",
    "    # for all sentences of a given length would sum to one.\n",
    "    N = len(words)\n",
    "    for w in sent_words:\n",
    "        \n",
    "        prob = freq_unigrams[w]/N    # XXXXX\n",
    "        prob_unigrams *= prob\n",
    "        \n",
    "        #entropy += -math.log(prob,2)\n",
    "        \n",
    "        print(w, '\\t', freq_unigrams[w], \n",
    "                 '\\t', len(words), '\\t', prob)\n",
    "    \n",
    "    #end_tag = '</s>'\n",
    "    #open_tag = '<s>'\n",
    "    \n",
    "    entropy = -math.log(prob_unigrams,2)\n",
    "    #prob_unigrams *= freq_unigrams[end_tag]/N\n",
    "    geom_mean_prob = math.pow(prob_unigrams, 1/len(sent_words))\n",
    "    \n",
    "    # Perplexity\n",
    "    #PP = math.pow(2, entropy/(N-1))\n",
    "    PP = math.pow(2, entropy/len(sent_words))\n",
    "    \n",
    "    #print(end_tag, '\\t', freq_unigrams[end_tag], \n",
    "    #             '\\t', len(sent_words), '\\t', freq_unigrams[end_tag]/N)\n",
    "    print('=====================================================')\n",
    "    \n",
    "    print('Prob. unigrams: ' + str(prob_unigrams))\n",
    "    print('Geometric mean prob.: ' + str(geom_mean_prob))\n",
    "    #print('Entropy rate: ' + str(entropy/(N-1)))\n",
    "    print('Entropy rate: ' + str(entropy/len(sent_words)))\n",
    "    print('Perplexity: ' + str(PP))\n",
    "    \n",
    "    return PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['det', 'var', 'en', 'gång', 'en', 'katt', 'som', 'hette', 'nils', '</s>']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'det var en gång en katt som hette nils </s>'\n",
    "sent_words = sentence.split()\n",
    "sent_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi      C(wi)      #words      P(wi)\n",
      "=====================================================\n",
      "det \t 21108 \t 1041560 \t 0.020265755213333847\n",
      "var \t 12090 \t 1041560 \t 0.011607588617074388\n",
      "en \t 13514 \t 1041560 \t 0.01297476861630631\n",
      "gång \t 1332 \t 1041560 \t 0.001278850954337724\n",
      "en \t 13514 \t 1041560 \t 0.01297476861630631\n",
      "katt \t 16 \t 1041560 \t 1.5361573025077767e-05\n",
      "som \t 16288 \t 1041560 \t 0.015638081339529167\n",
      "hette \t 97 \t 1041560 \t 9.312953646453396e-05\n",
      "nils \t 87 \t 1041560 \t 8.352855332386037e-05\n",
      "</s> \t 59047 \t 1041560 \t 0.056690925150735434\n",
      "=====================================================\n",
      "Prob. unigrams: 5.3651155337425844e-27\n",
      "Geometric mean prob.: 0.0023602494649885993\n",
      "Entropy rate: 8.726844932328587\n",
      "Perplexity: 423.68402782577465\n"
     ]
    }
   ],
   "source": [
    "perplexity_unigrams = unigram_lm(frequency, sent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_unigrams = int(perplexity_unigrams)\n",
    "perplexity_unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a program to compute the **sentence probability** using bigrams. Your function will tabulate and print the results as below. It will return the **perplexity**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "=====================================================\n",
    "wi \t wi+1 \t Ci,i+1 \t C(i) \t P(wi+1|wi)\n",
    "=====================================================\n",
    "<s>\t det \t 5672 \t 59047 \t 0.09605907158704083\n",
    "det \t var \t 3839 \t 21108 \t 0.1818741709304529\n",
    "var \t en \t 712 \t 12090 \t 0.058891645988420185\n",
    "en \t gång \t 706 \t 13514 \t 0.052242119283705785\n",
    "gång \t en \t 20 \t 1332 \t 0.015015015015015015\n",
    "en \t katt \t 6 \t 13514 \t 0.0004439840165754033\n",
    "katt \t som \t 2 \t 16 \t 0.125\n",
    "som \t hette \t 45 \t 16288 \t 0.002762770137524558\n",
    "hette \t nils \t 0 \t 97 \t 0.0 \t *backoff: \t 8.352285982272032e-05\n",
    "nils \t </s> \t 2 \t 87 \t 0.022988505747126436\n",
    "=====================================================\n",
    "Prob. bigrams:\t 2.376007803503683e-19\n",
    "Geometric mean prob.: 0.013727289294133601\n",
    "Entropy rate:\t 6.186809422848149\n",
    "Perplexity:\t 72.84759420254609\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def bigram_lm(freq_unigrams, freq_bigrams, sent_words):\n",
    "    print('=====================================================')\n",
    "    print('wi      wi+1      Ci,i+1      C(i)      P(wi+1|wi)')\n",
    "    print('=====================================================')\n",
    "    \n",
    "    #sentence = {}\n",
    "    # entropy\n",
    "    #entropy = 0\n",
    "    prob_bigrams = 1\n",
    "    # We need the end-symbol to make the bigram grammar a true probability \n",
    "    # distribution. Without an end-symbol, the sentence probabilities \n",
    "    # for all sentences of a given length would sum to one.\n",
    "    N = len(words)\n",
    "    for i in range(len(sent_words) - 1):\n",
    "    #for i in range(len(sent_words)):\n",
    "        if ((sent_words[i], sent_words[i+1]) in freq_bigrams):\n",
    "            ci_inext = freq_bigrams[(sent_words[i], sent_words[i+1])]\n",
    "            ci = freq_unigrams[(sent_words[i])]\n",
    "            \n",
    "            #prob_bi *= frequency_bigrams[(sent_words[i], \n",
    "           #             sent_words[i + 1])] / frequency[sent_words[i]]\n",
    "            \n",
    "            prob = ci_inext/ci    # XXXXXX    \n",
    "            #prob_unigrams *= prob\n",
    "            print(sent_words[i], '\\t', sent_words[i+1], '\\t', \n",
    "                  str(ci_inext), '\\t', str(ci), '\\t', prob)\n",
    "        else:\n",
    "            prob = freq_unigrams[sent_words[i+1]]/len(words)\n",
    "            print(sent_words[i], '\\t', sent_words[i+1], '\\t', \n",
    "                  '0', '\\t', str(freq_unigrams[sent_words[i]]), '\\t',\n",
    "                  '0.0 *backoff: ', str(prob))\n",
    "                                \n",
    "        prob_bigrams *= prob\n",
    "        \n",
    "    #end_tag = '</s>'\n",
    "    #open_tag = '<s>'\n",
    "    \n",
    "    entropy = -math.log(prob_bigrams,2)\n",
    "    geom_mean_prob = math.pow(prob_bigrams, 1/(len(sent_words) - 1))\n",
    "    \n",
    "    # Perplexity\n",
    "    #PP = math.pow(2, entropy/(N-1))\n",
    "    PP = math.pow(2, entropy/(len(sent_words) - 1))\n",
    "    \n",
    "    #print(end_tag, '\\t', freq_unigrams[end_tag], \n",
    "    #             '\\t', len(sent_words), '\\t', freq_unigrams[end_tag]/N)\n",
    "    print('=====================================================')\n",
    "    \n",
    "    print('Prob. bigrams: ' + str(prob_bigrams))\n",
    "    print('Geometric mean prob.: ' + str(geom_mean_prob))\n",
    "    #print('Entropy rate: ' + str(entropy/(N-1)))\n",
    "    print('Entropy rate: ' + str(entropy/(len(sent_words) - 1)))\n",
    "    print('Perplexity: ' + str(PP))\n",
    "    \n",
    "    return PP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'det',\n",
       " 'var',\n",
       " 'en',\n",
       " 'gång',\n",
       " 'en',\n",
       " 'katt',\n",
       " 'som',\n",
       " 'hette',\n",
       " 'nils',\n",
       " '</s>']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '<s> det var en gång en katt som hette nils </s>'\n",
    "sent_words = sentence.split()\n",
    "sent_words\n",
    "#len(sent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi      wi+1      Ci,i+1      C(i)      P(wi+1|wi)\n",
      "=====================================================\n",
      "<s> \t det \t 5672 \t 59047 \t 0.09605907158704083\n",
      "det \t var \t 3839 \t 21108 \t 0.1818741709304529\n",
      "var \t en \t 712 \t 12090 \t 0.058891645988420185\n",
      "en \t gång \t 706 \t 13514 \t 0.052242119283705785\n",
      "gång \t en \t 20 \t 1332 \t 0.015015015015015015\n",
      "en \t katt \t 6 \t 13514 \t 0.0004439840165754033\n",
      "katt \t som \t 2 \t 16 \t 0.125\n",
      "som \t hette \t 45 \t 16288 \t 0.002762770137524558\n",
      "hette \t nils \t 0 \t 97 \t 0.0 *backoff:  8.352855332386037e-05\n",
      "nils \t </s> \t 2 \t 87 \t 0.022988505747126436\n",
      "=====================================================\n",
      "Prob. bigrams: 2.376169768780815e-19\n",
      "Geometric mean prob.: 0.013727382866049192\n",
      "Entropy rate: 6.186799588766882\n",
      "Perplexity: 72.84709764111103\n"
     ]
    }
   ],
   "source": [
    "perplexity_bigrams = bigram_lm(frequency, frequency_bigrams, sent_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_bigrams = int(perplexity_bigrams)\n",
    "perplexity_bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In addition to this sentence, _Det var en gång en katt som hette Nils_, write five other sentences that will form your **test set** and run your programs on them. You will insert them in your report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five sentences - Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lite', 'kunskap', 'är', 'en', 'farlig', 'sak', '</s>']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A little knowledge is a dangerous thing\n",
    "sentence1 = 'lite kunskap är en farlig sak </s>'\n",
    "sent_words1 = sentence1.split()\n",
    "sent_words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi      C(wi)      #words      P(wi)\n",
      "=====================================================\n",
      "lite \t 45 \t 1041560 \t 4.320442413303122e-05\n",
      "kunskap \t 14 \t 1041560 \t 1.3441376396943047e-05\n",
      "är \t 6290 \t 1041560 \t 0.006039018395483697\n",
      "en \t 13514 \t 1041560 \t 0.01297476861630631\n",
      "farlig \t 40 \t 1041560 \t 3.840393256269442e-05\n",
      "sak \t 205 \t 1041560 \t 0.0001968201543838089\n",
      "</s> \t 59047 \t 1041560 \t 0.056690925150735434\n",
      "=====================================================\n",
      "Prob. unigrams: 1.9498300024612508e-23\n",
      "Geometric mean prob.: 0.0005697886857557694\n",
      "Entropy rate: 10.777285405072845\n",
      "Perplexity: 1755.0366039185164\n"
     ]
    }
   ],
   "source": [
    "perplexity_unigrams1 = unigram_lm(frequency, sent_words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tidigt',\n",
       " 'till',\n",
       " 'sängs',\n",
       " 'och',\n",
       " 'tidigt',\n",
       " 'att',\n",
       " 'stiga',\n",
       " 'gör',\n",
       " 'en',\n",
       " 'man',\n",
       " 'frisk',\n",
       " '</s>']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Early to bed and early to rise, makes a man healthy, wealthy and wise\n",
    "sentence2 = 'tidigt till sängs och tidigt att stiga gör en man frisk </s>'\n",
    "sent_words2 = sentence2.split()\n",
    "sent_words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi      C(wi)      #words      P(wi)\n",
      "=====================================================\n",
      "tidigt \t 38 \t 1041560 \t 3.64837359345597e-05\n",
      "till \t 9139 \t 1041560 \t 0.008774338492261608\n",
      "sängs \t 18 \t 1041560 \t 1.728176965321249e-05\n",
      "och \t 36356 \t 1041560 \t 0.03490533430623296\n",
      "tidigt \t 38 \t 1041560 \t 3.64837359345597e-05\n",
      "att \t 28020 \t 1041560 \t 0.02690195476016744\n",
      "stiga \t 90 \t 1041560 \t 8.640884826606244e-05\n",
      "gör \t 355 \t 1041560 \t 0.000340834901493913\n",
      "en \t 13514 \t 1041560 \t 0.01297476861630631\n",
      "man \t 2322 \t 1041560 \t 0.002229348285264411\n",
      "frisk \t 69 \t 1041560 \t 6.624678367064787e-05\n",
      "</s> \t 59047 \t 1041560 \t 0.056690925150735434\n",
      "=====================================================\n",
      "Prob. unigrams: 6.063662305241324e-37\n",
      "Geometric mean prob.: 0.0009591677848954893\n",
      "Entropy rate: 10.025929175084222\n",
      "Perplexity: 1042.570461339003\n"
     ]
    }
   ],
   "source": [
    "perplexity_unigrams2 = unigram_lm(frequency, sent_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ju', 'större', 'de', 'är', 'desto', 'hårdare', 'faller', 'de', '</s>']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The bigger they are, the harder they fall\n",
    "sentence3 = 'ju större de är desto hårdare faller de </s>'\n",
    "sent_words3 = sentence3.split()\n",
    "sent_words3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi      C(wi)      #words      P(wi)\n",
      "=====================================================\n",
      "ju \t 1250 \t 1041560 \t 0.0012001228925842006\n",
      "större \t 150 \t 1041560 \t 0.00014401474711010407\n",
      "de \t 11942 \t 1041560 \t 0.011465494066592419\n",
      "är \t 6290 \t 1041560 \t 0.006039018395483697\n",
      "desto \t 44 \t 1041560 \t 4.224432581896386e-05\n",
      "hårdare \t 8 \t 1041560 \t 7.680786512538884e-06\n",
      "faller \t 47 \t 1041560 \t 4.5124620761165944e-05\n",
      "de \t 11942 \t 1041560 \t 0.011465494066592419\n",
      "</s> \t 59047 \t 1041560 \t 0.056690925150735434\n",
      "=====================================================\n",
      "Prob. unigrams: 1.1389004736737127e-28\n",
      "Geometric mean prob.: 0.0007855341786154558\n",
      "Entropy rate: 10.314038330960237\n",
      "Perplexity: 1273.019083348546\n"
     ]
    }
   ],
   "source": [
    "perplexity_unigrams3 = unigram_lm(frequency, sent_words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hur',\n",
       " 'vacker',\n",
       " 'skulle',\n",
       " 'världen',\n",
       " 'vara',\n",
       " 'om',\n",
       " 'det',\n",
       " 'fanns',\n",
       " 'en',\n",
       " 'regel',\n",
       " 'för',\n",
       " 'att',\n",
       " 'gå',\n",
       " 'runt',\n",
       " 'i',\n",
       " 'labyrinter',\n",
       " '</s>']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How beautiful would be the world if there were a rule for going round in labyrinths\n",
    "sentence4 = 'hur vacker skulle världen vara om det fanns en regel för att gå runt i labyrinter </s>'\n",
    "sent_words4 = sentence4.split()\n",
    "sent_words4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi      C(wi)      #words      P(wi)\n",
      "=====================================================\n",
      "hur \t 1996 \t 1041560 \t 0.0019163562348784515\n",
      "vacker \t 209 \t 1041560 \t 0.00020066054764007835\n",
      "skulle \t 5433 \t 1041560 \t 0.00521621414032797\n",
      "världen \t 363 \t 1041560 \t 0.00034851568800645187\n",
      "vara \t 1803 \t 1041560 \t 0.001731057260263451\n",
      "om \t 8075 \t 1041560 \t 0.007752793886093936\n",
      "det \t 21108 \t 1041560 \t 0.020265755213333847\n",
      "fanns \t 702 \t 1041560 \t 0.0006739890164752871\n",
      "en \t 13514 \t 1041560 \t 0.01297476861630631\n",
      "regel \t 2 \t 1041560 \t 1.920196628134721e-06\n",
      "för \t 9443 \t 1041560 \t 0.009066208379738086\n",
      "att \t 28020 \t 1041560 \t 0.02690195476016744\n",
      "gå \t 1590 \t 1041560 \t 0.0015265563193671032\n",
      "runt \t 154 \t 1041560 \t 0.0001478551403663735\n",
      "i \t 16508 \t 1041560 \t 0.015849302968623986\n",
      "labyrinter \t 1 \t 1041560 \t 9.600983140673605e-07\n",
      "</s> \t 59047 \t 1041560 \t 0.056690925150735434\n",
      "=====================================================\n",
      "Prob. unigrams: 1.5161591885734908e-49\n",
      "Geometric mean prob.: 0.001343628187008172\n",
      "Entropy rate: 9.539650318399216\n",
      "Perplexity: 744.2535142305092\n"
     ]
    }
   ],
   "source": [
    "perplexity_unigrams4 = unigram_lm(frequency, sent_words4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['se', 'inget', 'ont', 'hör', 'inget', 'ont', 'tala', 'inget', 'ont', '</s>']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See no evil, hear no evil, speak no evil\n",
    "sentence5 = 'se inget ont hör inget ont tala inget ont </s>'\n",
    "sent_words5 = sentence5.split()\n",
    "sent_words5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi      C(wi)      #words      P(wi)\n",
      "=====================================================\n",
      "se \t 1989 \t 1041560 \t 0.00190963554667998\n",
      "inget \t 34 \t 1041560 \t 3.264334267829026e-05\n",
      "ont \t 150 \t 1041560 \t 0.00014401474711010407\n",
      "hör \t 222 \t 1041560 \t 0.00021314182572295404\n",
      "inget \t 34 \t 1041560 \t 3.264334267829026e-05\n",
      "ont \t 150 \t 1041560 \t 0.00014401474711010407\n",
      "tala \t 845 \t 1041560 \t 0.0008112830753869196\n",
      "inget \t 34 \t 1041560 \t 3.264334267829026e-05\n",
      "ont \t 150 \t 1041560 \t 0.00014401474711010407\n",
      "</s> \t 59047 \t 1041560 \t 0.056690925150735434\n",
      "=====================================================\n",
      "Prob. unigrams: 1.9449565461801393e-36\n",
      "Geometric mean prob.: 0.00026846704976591837\n",
      "Entropy rate: 11.862967349276994\n",
      "Perplexity: 3724.85189848035\n"
     ]
    }
   ],
   "source": [
    "perplexity_unigrams5 = unigram_lm(frequency, sent_words5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Five sentences - Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'lite', 'kunskap', 'är', 'en', 'farlig', 'sak', '</s>']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A little knowledge is a dangerous thing\n",
    "sentence1 = '<s> lite kunskap är en farlig sak </s>'\n",
    "sent_words1 = sentence1.split()\n",
    "sent_words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi      wi+1      Ci,i+1      C(i)      P(wi+1|wi)\n",
      "=====================================================\n",
      "<s> \t lite \t 0 \t 59047 \t 0.0 *backoff:  4.320442413303122e-05\n",
      "lite \t kunskap \t 0 \t 45 \t 0.0 *backoff:  1.3441376396943047e-05\n",
      "kunskap \t är \t 0 \t 14 \t 0.0 *backoff:  0.006039018395483697\n",
      "är \t en \t 304 \t 6290 \t 0.04833068362480127\n",
      "en \t farlig \t 6 \t 13514 \t 0.0004439840165754033\n",
      "farlig \t sak \t 0 \t 40 \t 0.0 *backoff:  0.0001968201543838089\n",
      "sak \t </s> \t 34 \t 205 \t 0.16585365853658537\n",
      "=====================================================\n",
      "Prob. bigrams: 2.4565364591697616e-21\n",
      "Geometric mean prob.: 0.0011369999855527747\n",
      "Entropy rate: 9.78055204876345\n",
      "Perplexity: 879.5074869889572\n"
     ]
    }
   ],
   "source": [
    "perplexity_bigrams1 = bigram_lm(frequency, frequency_bigrams, sent_words1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'tidigt',\n",
       " 'till',\n",
       " 'sängs',\n",
       " 'och',\n",
       " 'tidigt',\n",
       " 'att',\n",
       " 'stiga',\n",
       " 'gör',\n",
       " 'en',\n",
       " 'man',\n",
       " 'frisk',\n",
       " '</s>']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Early to bed and early to rise, makes a man healthy, wealthy and wise\n",
    "sentence2 = '<s> tidigt till sängs och tidigt att stiga gör en man frisk </s>'\n",
    "sent_words2 = sentence2.split()\n",
    "sent_words2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi      wi+1      Ci,i+1      C(i)      P(wi+1|wi)\n",
      "=====================================================\n",
      "<s> \t tidigt \t 3 \t 59047 \t 5.080698426677054e-05\n",
      "tidigt \t till \t 1 \t 38 \t 0.02631578947368421\n",
      "till \t sängs \t 18 \t 9139 \t 0.001969580916949338\n",
      "sängs \t och \t 1 \t 18 \t 0.05555555555555555\n",
      "och \t tidigt \t 1 \t 36356 \t 2.750577621300473e-05\n",
      "tidigt \t att \t 2 \t 38 \t 0.05263157894736842\n",
      "att \t stiga \t 28 \t 28020 \t 0.0009992862241256246\n",
      "stiga \t gör \t 0 \t 90 \t 0.0 *backoff:  0.000340834901493913\n",
      "gör \t en \t 6 \t 355 \t 0.016901408450704224\n",
      "en \t man \t 117 \t 13514 \t 0.008657688323220364\n",
      "man \t frisk \t 0 \t 2322 \t 0.0 *backoff:  6.624678367064787e-05\n",
      "frisk \t </s> \t 10 \t 69 \t 0.14492753623188406\n",
      "=====================================================\n",
      "Prob. bigrams: 1.0134118069871207e-31\n",
      "Geometric mean prob.: 0.002613056679059623\n",
      "Entropy rate: 8.580045866582262\n",
      "Perplexity: 382.69357416306656\n"
     ]
    }
   ],
   "source": [
    "perplexity_bigrams2 = bigram_lm(frequency, frequency_bigrams, sent_words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'ju', 'större', 'de', 'är', 'desto', 'hårdare', 'faller', 'de', '</s>']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The bigger they are, the harder they fall\n",
    "sentence3 = '<s> ju större de är desto hårdare faller de </s>'\n",
    "sent_words3 = sentence3.split()\n",
    "sent_words3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi      wi+1      Ci,i+1      C(i)      P(wi+1|wi)\n",
      "=====================================================\n",
      "<s> \t ju \t 21 \t 59047 \t 0.00035564888986739377\n",
      "ju \t större \t 0 \t 1250 \t 0.0 *backoff:  0.00014401474711010407\n",
      "större \t de \t 0 \t 150 \t 0.0 *backoff:  0.011465494066592419\n",
      "de \t är \t 59 \t 11942 \t 0.004940545972198961\n",
      "är \t desto \t 0 \t 6290 \t 0.0 *backoff:  4.224432581896386e-05\n",
      "desto \t hårdare \t 0 \t 44 \t 0.0 *backoff:  7.680786512538884e-06\n",
      "hårdare \t faller \t 0 \t 8 \t 0.0 *backoff:  4.5124620761165944e-05\n",
      "faller \t de \t 0 \t 47 \t 0.0 *backoff:  0.011465494066592419\n",
      "de \t </s> \t 102 \t 11942 \t 0.008541282867191425\n",
      "=====================================================\n",
      "Prob. bigrams: 4.160060663585748e-30\n",
      "Geometric mean prob.: 0.0005438204290664426\n",
      "Entropy rate: 10.844582031130408\n",
      "Perplexity: 1838.842284238317\n"
     ]
    }
   ],
   "source": [
    "perplexity_bigrams3 = bigram_lm(frequency, frequency_bigrams, sent_words3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'hur',\n",
       " 'vacker',\n",
       " 'skulle',\n",
       " 'världen',\n",
       " 'vara',\n",
       " 'om',\n",
       " 'det',\n",
       " 'fanns',\n",
       " 'en',\n",
       " 'regel',\n",
       " 'för',\n",
       " 'att',\n",
       " 'gå',\n",
       " 'runt',\n",
       " 'i',\n",
       " 'labyrinter',\n",
       " '</s>']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How beautiful would be the world if there were a rule for going round in labyrinths\n",
    "sentence4 = '<s> hur vacker skulle världen vara om det fanns en regel för att gå runt i labyrinter </s>'\n",
    "sent_words4 = sentence4.split()\n",
    "sent_words4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi      wi+1      Ci,i+1      C(i)      P(wi+1|wi)\n",
      "=====================================================\n",
      "<s> \t hur \t 238 \t 59047 \t 0.004030687418497129\n",
      "hur \t vacker \t 3 \t 1996 \t 0.001503006012024048\n",
      "vacker \t skulle \t 0 \t 209 \t 0.0 *backoff:  0.00521621414032797\n",
      "skulle \t världen \t 0 \t 5433 \t 0.0 *backoff:  0.00034851568800645187\n",
      "världen \t vara \t 0 \t 363 \t 0.0 *backoff:  0.001731057260263451\n",
      "vara \t om \t 5 \t 1803 \t 0.0027731558513588465\n",
      "om \t det \t 558 \t 8075 \t 0.06910216718266254\n",
      "det \t fanns \t 253 \t 21108 \t 0.011985976880803486\n",
      "fanns \t en \t 74 \t 702 \t 0.10541310541310542\n",
      "en \t regel \t 1 \t 13514 \t 7.399733609590054e-05\n",
      "regel \t för \t 0 \t 2 \t 0.0 *backoff:  0.009066208379738086\n",
      "för \t att \t 2932 \t 9443 \t 0.3104945462247167\n",
      "att \t gå \t 360 \t 28020 \t 0.01284796573875803\n",
      "gå \t runt \t 3 \t 1590 \t 0.0018867924528301887\n",
      "runt \t i \t 13 \t 154 \t 0.08441558441558442\n",
      "i \t labyrinter \t 0 \t 16508 \t 0.0 *backoff:  9.600983140673605e-07\n",
      "labyrinter \t </s> \t 1 \t 1 \t 1.0\n",
      "=====================================================\n",
      "Prob. bigrams: 1.88910284270759e-39\n",
      "Geometric mean prob.: 0.005273909614054819\n",
      "Entropy rate: 7.566911438615527\n",
      "Perplexity: 189.61265421292558\n"
     ]
    }
   ],
   "source": [
    "perplexity_bigrams4 = bigram_lm(frequency, frequency_bigrams, sent_words4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>',\n",
       " 'se',\n",
       " 'inget',\n",
       " 'ont',\n",
       " 'hör',\n",
       " 'inget',\n",
       " 'ont',\n",
       " 'tala',\n",
       " 'inget',\n",
       " 'ont',\n",
       " '</s>']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See no evil, hear no evil, speak no evil\n",
    "sentence5 = '<s> se inget ont hör inget ont tala inget ont </s>'\n",
    "sent_words5 = sentence5.split()\n",
    "sent_words5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================\n",
      "wi      wi+1      Ci,i+1      C(i)      P(wi+1|wi)\n",
      "=====================================================\n",
      "<s> \t se \t 196 \t 59047 \t 0.003319389638762342\n",
      "se \t inget \t 0 \t 1989 \t 0.0 *backoff:  3.264334267829026e-05\n",
      "inget \t ont \t 6 \t 34 \t 0.17647058823529413\n",
      "ont \t hör \t 0 \t 150 \t 0.0 *backoff:  0.00021314182572295404\n",
      "hör \t inget \t 0 \t 222 \t 0.0 *backoff:  3.264334267829026e-05\n",
      "inget \t ont \t 6 \t 34 \t 0.17647058823529413\n",
      "ont \t tala \t 0 \t 150 \t 0.0 *backoff:  0.0008112830753869196\n",
      "tala \t inget \t 0 \t 845 \t 0.0 *backoff:  3.264334267829026e-05\n",
      "inget \t ont \t 6 \t 34 \t 0.17647058823529413\n",
      "ont \t </s> \t 23 \t 150 \t 0.15333333333333332\n",
      "=====================================================\n",
      "Prob. bigrams: 1.682429136522422e-26\n",
      "Geometric mean prob.: 0.002646023385115938\n",
      "Entropy rate: 8.561958472689598\n",
      "Perplexity: 377.92560928413127\n"
     ]
    }
   ],
   "source": [
    "perplexity_bigrams5 = bigram_lm(frequency, frequency_bigrams, sent_words5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Online prediction of words <a name=\"t5\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now carry out an online prediction of words. You will consider two cases:\n",
    "1. Prediction of the **current word** a user is typing;\n",
    "2. Prediction of the **next word**.\n",
    "\n",
    "Ideally, you would write a **loop** that reads the words and apply the models while typing. As the Jupyter labs are not designed for **interactive** input and output, we will simplify the experimental settings with **constant strings** at a given time of the input.  \n",
    "\n",
    "We will assume the user is typing the phrase: _Det var en gång_. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To have a more accurate prediction, you will use a **trigram counting** function. Program it following the model of bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code\n",
    "def trigrams(words):\n",
    "    trigrams = []\n",
    "    for i in range(len(words) - 3 + 1):\n",
    "        trigrams.append(tuple(words[i : i+3]))\n",
    "        \n",
    "    frequency_trigrams = {}\n",
    "    #for i in range(len(words) - 3 + 1):\n",
    "    for gram in trigrams:\n",
    "        #if trigrams[i] in frequency_trigrams:\n",
    "        if gram in frequency_trigrams:\n",
    "            frequency_trigrams[gram] += 1\n",
    "        else:\n",
    "            frequency_trigrams[gram] = 1\n",
    "    return frequency_trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency_trigrams = trigrams(words)\n",
    "frequency_trigrams[('det', 'var', 'en')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user starts typing _Det var en gång_. After the 2nd character, your program tries to help the user with suggested words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "starting_text = 'De'.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a program to rank the **five first candidates** at this point. Assign these predictions in a **list** that you will call `current_word_predictions_1`. Note that you are starting a sentence and you can then use the **bigram frequencies**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "cand_nbr = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "current_word_predictions_1 = []\n",
    "predictions = []\n",
    "for bigram in sorted(frequency_bigrams.keys(), \n",
    "                   key=frequency_bigrams.get, reverse=True):\n",
    "    #print(bigram)\n",
    "    #print(bigram[0])\n",
    "    if (bigram[0] == '<s>'):\n",
    "        if (bigram[1][:2] == starting_text):\n",
    "            #print(bigram)\n",
    "            #print(frequency_bigrams[bigram])\n",
    "            predictions.append(bigram[1])\n",
    "for i in range(cand_nbr):\n",
    "    current_word_predictions_1.append(predictions[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['det', 'de', 'den', 'detta', 'denna']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_word_predictions_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let us now suppose that the user has typed: _Det var en_. After detecting a **space**, your program starts predicting a next possible word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_text = \"Det var en \".lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize this text and return a list of tokens. Call it `tokens`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "tokens = tokenize(current_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['det', 'var', 'en']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to propose the five next possible words ranked by frequency using a **trigram model**. Assign these predictions to a variable that you will call `next_word_predictions`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-gram looks three words into the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "next_word_predictions = []\n",
    "tri_predictions = []\n",
    "for trigram in sorted(frequency_trigrams.keys(), \n",
    "                   key=frequency_trigrams.get, reverse=True):\n",
    "    #print(trigram)\n",
    "    #print(trigram[0:2])\n",
    "    #if (trigram[0] == token[1]):\n",
    "    #print(tokens[1:3])\n",
    "    if (trigram[0:2] == tuple(tokens[1:3])):\n",
    "        #print(trigram)\n",
    "        #print(frequency_trigrams[trigram])\n",
    "        tri_predictions.append(trigram[2])\n",
    "for i in range(cand_nbr):\n",
    "    next_word_predictions.append(tri_predictions[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['stor', 'liten', 'gammal', 'god', 'sådan']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_word_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finally, let us suppose that the user has typed _Det var en g_, rank the five possible candidates. Assign these predictions in a list that you will call `current_word_predictions_2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_text = \"Det var en g\".lower()\n",
    "#current_text[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "current_word_predictions_2 = []\n",
    "current_tri_predictions = []\n",
    "for trigram in sorted(frequency_trigrams.keys(), \n",
    "                   key=frequency_trigrams.get, reverse=True):\n",
    "    #print(trigram)\n",
    "    #print(trigram[0:2])\n",
    "    #if (trigram[0] == token[1]):\n",
    "    #print(tokens[1:3])\n",
    "    if (trigram[0:2] == tuple(tokens[1:3])):\n",
    "        #print(trigram)\n",
    "        #print(frequency_trigrams[trigram])\n",
    "        if (trigram[2][0:1] == current_text[-1]):\n",
    "            current_tri_predictions.append(trigram[2])\n",
    "            \n",
    "for i in range(cand_nbr):\n",
    "    current_word_predictions_2.append(current_tri_predictions[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gammal', 'god', 'gång', 'ganska', 'grann']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_word_predictions_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checked answers <a name=\"t6\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The system will check these answers: `(perplexity_unigrams, perplexity_bigrams, current_word_predictions_1, next_word_predictions, current_word_predictions_2)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(423,\n",
       " 72,\n",
       " ['det', 'de', 'den', 'detta', 'denna'],\n",
       " ['stor', 'liten', 'gammal', 'god', 'sådan'],\n",
       " ['gammal', 'god', 'gång', 'ganska', 'grann'])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(perplexity_unigrams, perplexity_bigrams, current_word_predictions_1, next_word_predictions, current_word_predictions_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission <a name=\"t7\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have written all the code and run all the cells, fill in your ID and as well as the name of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "STIL_ID = [\"hi8826mo-s\"] # Write your stil ids as a list\n",
    "CURRENT_NOTEBOOK_PATH = os.path.join(os.getcwd(), \n",
    "                                     \"2-language_models_HichamMohamad.ipynb\") # Write the name of your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission code will send your answer. It consists of the perplexities and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(423, 72, ['det', 'de', 'den', 'detta', 'denna'], ['stor', 'liten', 'gammal', 'god', 'sådan'], ['gammal', 'god', 'gång', 'ganska', 'grann'])\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ANSWER = str((perplexity_unigrams, perplexity_bigrams, current_word_predictions_1, next_word_predictions, current_word_predictions_2))\n",
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the moment of truth:\n",
    "1. Save your notebook and\n",
    "2. Run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_NOTEBOOK_PATH = CURRENT_NOTEBOOK_PATH + \".submission.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSIGNMENT = 2\n",
    "API_KEY = \"f581ba347babfea0b8f2c74a3a6776a7\"\n",
    "\n",
    "# Copy and compress current notebook\n",
    "with bz2.open(SUBMISSION_NOTEBOOK_PATH, mode=\"wb\") as fout:\n",
    "    with open(CURRENT_NOTEBOOK_PATH, \"rb\") as fin:\n",
    "        fout.write(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msg': None,\n",
       " 'status': 'correct',\n",
       " 'signature': '4e1e0f6dcf3c7b185cb3460ba5e0e24f5155363685baa53dbdad76008a8eed1785be88917315df56c998a17f3b514b67024d4e7321231c6aeab661f1f5c11b29',\n",
       " 'submission_id': '801a964c-dc25-4cb1-8316-0515f94e985b'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = requests.post(\"https://vilde.cs.lth.se/edan20checker/submit\", \n",
    "                    files={\"notebook_file\": open(SUBMISSION_NOTEBOOK_PATH, \"rb\")}, \n",
    "                    data={\n",
    "                        \"stil_id\": STIL_ID,\n",
    "                        \"assignment\": ASSIGNMENT,\n",
    "                        \"answer\": ANSWER,\n",
    "                        \"api_key\": API_KEY,\n",
    "                    },\n",
    "                   verify=True)\n",
    "\n",
    "# from IPython.display import display, JSON\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading <a name=\"t8\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As an application of <b>n-grams</b>, execute the Jupyter notebook by Peter Norvig <a\n",
    "        href=\"http://nbviewer.jupyter.org/url/norvig.com/ipython/How%20to%20Do%20Things%20with%20Words.ipynb\">\n",
    "    here</a>. Just run all the cells and be sure that you understand the code.\n",
    "    You will find the data <a href=\"http://norvig.com/ngrams/\">here</a>.</p>\n",
    "<p>In your report, you will also <b>describe one experiment with a long string of words</b>\n",
    "    you will create yourself or copy from a text you like. You will remove all the punctuation and\n",
    "    white spaces from this string. Set this string in lowercase letters.</p>\n",
    "<p>You will just add a cell at the end of Sect. 7 in Norvig's notebook, where you will use your string and\n",
    "    run the notebook cell with the <b>segment()</b> and <b>segment2()</b> functions. </p>\n",
    "<p>You will <b>comment the segmentation results</b> you obtain with unigram and bigram models.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
