{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment #5: Extraction of subject–verb–object triples\n",
    "\n",
    "#### Author: Hicham Mohamad (hi8826mo-s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Swedish Talbanken Corpus](#t1)\n",
    "2. [Extracting the subject-verb pairs](#t2)\n",
    "3. [Extracting the subject-verb-object triples](#t3)\n",
    "4. [Multilingual Corpora](#t4)\n",
    "5. [Resolving the entities](#t5)\n",
    "6. [Mapping the entities, optional](#t6)\n",
    "7. [Reading](#t7)\n",
    "8. [Submission](#t8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will extract **relations** from a **parsed sentence** involving two words or entities. You will start with pairs of words, namely a subject and its verb, and then extend your programs to triples: subject, verb, and object. In the triples, the subject and the object are the **entities**, and the verb represents the **relation**. \n",
    "\n",
    "$$\n",
    "\\text{Subject} \\xrightarrow[\\text{}]{\\text{Verb}} \\text{Object}\n",
    "$$\n",
    "\n",
    "The overall work is inspired by the _Prismatic_ **knowledge base** used in the **IBM Watson** system, where the subject, verb, and object **triples** are a way to extract knowledge from text.  See <a href=\"http://www.aclweb.org/anthology/W/W10/W10-0915.pdf\">this paper</a> for details. \n",
    "\n",
    "You will apply the **extraction** to multilingual texts: \n",
    "1. First you will use a **parsed corpus** of Swedish; and then\n",
    "2. You will apply it to other languages.\n",
    "            \n",
    "The objectives of this assignment are to:\n",
    "* Extract the **subject–verb pairs** from a parsed corpus\n",
    "* Extend the extraction to **subject–verb–object triples**\n",
    "* Understand how **dependency parsing** can help create a knowledge base\n",
    "* Write a short report of 1 to 2 pages on the assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As corpora, you will use the **Universal Dependencies**: https://universaldependencies.org/.\n",
    "1. In the first part of the assignment, you will focus on **Swedish** as it is easier to understand for most students, and then \n",
    "2. Move on to all the **other languages**. \n",
    "\n",
    "You will only consider the **training sets** of each corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing a parsed corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the latest version of **Universal dependencies (2.6)** and uncompress them. You have a local version in the `/usr/local/cs/EDAN20/` folder on LTH's machines;\n",
    "2. Go to the Swedish _Talbanken_ corpus;\n",
    "3. Read the **CoNLL-U annotation** here: https://universaldependencies.org/format.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examining the annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will carry out the following steps and describe them in your report:\n",
    "\n",
    "1. Draw **graphical representations** of the two first Swedish sentences of the training set. You will include these drawings in your report;\n",
    "2. Visualize these sentences with this tool: http://spyysalo.github.io/conllu.js/ and check that you have the same results;\n",
    "3. Apply the **dependency parser** for Swedish of the <a href=\"http://vilde.cs.lth.se:9000/\">Langforia pipelines</a> to these sentences (only the text of each sentence). You will have to select Swedish and activate both `Token` and `DependencyRelation`. Link to Lanforia pipelines: <a href=\"http://vilde.cs.lth.se:9000/\">http://vilde.cs.lth.se:9000/</a>. You will describe possible differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The two first Swedish sentences of the training set\n",
    "- Individuell beskattning av arbetsinkomster\n",
    "\n",
    "- Genom skattereformen införs individuell beskattning (särbeskattning) av arbetsinkomster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE: CoNLL-U Format\n",
    "\n",
    "\n",
    "We use a revised version of the CoNLL-X format called CoNLL-U. Annotations are encoded in plain text files (UTF-8, normalized to NFC, using only the LF character as line break, including an LF character at the end of file) with three types of lines:\n",
    "\n",
    "- **Word lines** containing the annotation of a word/token in 10 fields separated by single tab characters; see below.\n",
    "- Blank lines marking sentence boundaries.\n",
    "- Comment lines starting with hash (#).\n",
    "\n",
    "Sentences consist of one or more word lines, and word lines contain the following fields:\n",
    "\n",
    "ID: **Word index**, integer starting at 1 for each new sentence; may be a range for multiword tokens; may be a decimal number for empty nodes (decimal numbers can be lower than 1 but must be greater than 0). <br>\n",
    "FORM: Word form or punctuation symbol.<br>\n",
    "LEMMA: Lemma or stem of word form.<br>\n",
    "UPOS: Universal part-of-speech tag.<br>\n",
    "XPOS: Language-specific part-of-speech tag; underscore if not available.<br>\n",
    "FEATS: List of **morphological features** from the universal feature inventory or from a defined language-specific extension; underscore if not available. <br>\n",
    "HEAD: Head of the current word, which is either a value of ID or zero (0).<br>\n",
    "DEPREL: **Universal dependency relation** to the HEAD (root iff HEAD = 0) or a defined language-specific subtype of one.<br>\n",
    "DEPS: **Enhanced dependency graph** in the form of a list of head-deprel pairs.<br>\n",
    "MISC: Any other annotation.<br>\n",
    "\n",
    "The fields DEPS and MISC replace the obsolete fields PHEAD and PDEPREL of the CoNLL-X format. In addition, we have modified the usage of the ID, FORM, LEMMA, XPOS, FEATS and HEAD fields as explained below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Swedish <a name='t1'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will extract all the **subject–verb** pairs and the **subject–verb–object** triples from the **Swedish _Talbanken_** training corpus. To start the program, you can use the **CoNLL-U reader** available in the cells below.\n",
    "This program works for the other corpora. You can also program a reader yourself starting from the one you used to read the CoNLL 2000 format in the fourth lab or from scratch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus location "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the corpus locations you will use. You may have to adjust `ud_path`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ud_path = '../../corpus/ud-treebanks-v2.6/'\n",
    "ud_path = 'ud-treebanks-v2.6/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_sv = ud_path + 'UD_Swedish-Talbanken/sv_talbanken-ud-train.conllu'\n",
    "\n",
    "path_fr = ud_path + 'UD_French-GSD/fr_gsd-ud-train.conllu'\n",
    "path_ru = ud_path + 'UD_Russian-SynTagRus/ru_syntagrus-ud-train.conllu'\n",
    "path_en = ud_path + 'UD_English-EWT/en_ewt-ud-train.conllu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **column names** of the CoNLL-U corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names_u = ['ID', 'FORM', 'LEMMA', 'UPOS', 'XPOS', 'FEATS', 'HEAD', 'DEPREL', 'DEPS', 'MISC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to read the CoNLL-U files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_sentences(file):\n",
    "    \"\"\"\n",
    "    Creates a list of sentences from the corpus\n",
    "    Each sentence is a string\n",
    "    :param file:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    f = open(file, encoding='utf-8').read().strip()\n",
    "    sentences = f.split('\\n\\n')\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rows(sentences, column_names):\n",
    "    \"\"\"\n",
    "    Creates a list of sentence where each sentence is a list of lines\n",
    "    Each line is a dictionary of columns\n",
    "    :param sentences:\n",
    "    :param column_names:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    root_values = ['0', 'ROOT', 'ROOT', 'ROOT', 'ROOT', 'ROOT', '0', 'ROOT', '0', 'ROOT']\n",
    "    start = [dict(zip(column_names, root_values))]\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        rows = sentence.split('\\n')\n",
    "        sentence = [dict(zip(column_names, \n",
    "                             row.split('\\t'))) for row in rows if row[0] != '#']\n",
    "        sentence = start + sentence\n",
    "        new_sentences.append(sentence)\n",
    "        \n",
    "    return new_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the **Swedish Talbanken** corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = read_sentences(path_sv)\n",
    "formatted_corpus = split_rows(sentences, column_names_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4303"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formatted_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second **parsed sentence**: _Genom skattereformen införs individuell beskattning (särbeskattning) av arbetsinkomster._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ID': '0',\n",
       "  'FORM': 'ROOT',\n",
       "  'LEMMA': 'ROOT',\n",
       "  'UPOS': 'ROOT',\n",
       "  'XPOS': 'ROOT',\n",
       "  'FEATS': 'ROOT',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'ROOT',\n",
       "  'DEPS': '0',\n",
       "  'MISC': 'ROOT'},\n",
       " {'ID': '1',\n",
       "  'FORM': 'Genom',\n",
       "  'LEMMA': 'genom',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'PP',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '2',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '2:case',\n",
       "  'MISC': '_'},\n",
       " {'ID': '2',\n",
       "  'FORM': 'skattereformen',\n",
       "  'LEMMA': 'skattereform',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|DEF|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Def|Gender=Com|Number=Sing',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'obl',\n",
       "  'DEPS': '3:obl:genom',\n",
       "  'MISC': '_'},\n",
       " {'ID': '3',\n",
       "  'FORM': 'införs',\n",
       "  'LEMMA': 'införa',\n",
       "  'UPOS': 'VERB',\n",
       "  'XPOS': 'VB|PRS|SFO',\n",
       "  'FEATS': 'Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Pass',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': '0:root',\n",
       "  'MISC': '_'},\n",
       " {'ID': '4',\n",
       "  'FORM': 'individuell',\n",
       "  'LEMMA': 'individuell',\n",
       "  'UPOS': 'ADJ',\n",
       "  'XPOS': 'JJ|POS|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Degree=Pos|Gender=Com|Number=Sing',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'amod',\n",
       "  'DEPS': '5:amod',\n",
       "  'MISC': '_'},\n",
       " {'ID': '5',\n",
       "  'FORM': 'beskattning',\n",
       "  'LEMMA': 'beskattning',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'nsubj:pass',\n",
       "  'DEPS': '3:nsubj:pass',\n",
       "  'MISC': '_'},\n",
       " {'ID': '6',\n",
       "  'FORM': '(',\n",
       "  'LEMMA': '(',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'PAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '5:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '7',\n",
       "  'FORM': 'särbeskattning',\n",
       "  'LEMMA': 'särbeskattning',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'appos',\n",
       "  'DEPS': '5:appos',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '8',\n",
       "  'FORM': ')',\n",
       "  'LEMMA': ')',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'PAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '5:punct',\n",
       "  'MISC': '_'},\n",
       " {'ID': '9',\n",
       "  'FORM': 'av',\n",
       "  'LEMMA': 'av',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'PP',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '10:case',\n",
       "  'MISC': '_'},\n",
       " {'ID': '10',\n",
       "  'FORM': 'arbetsinkomster',\n",
       "  'LEMMA': 'arbetsinkomst',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|PLU|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Plur',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'nmod',\n",
       "  'DEPS': '5:nmod:av',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " {'ID': '11',\n",
       "  'FORM': '.',\n",
       "  'LEMMA': '.',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'MAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '3:punct',\n",
       "  'MISC': '_'}]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_corpus[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting the lists in dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ease the processing of some corpora, you will use a **dictionary** representation of the **sentences**. The keys will be the `ID` values. We do this because `ID` is not necessarily a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_dict(formatted_corpus):\n",
    "    \"\"\"\n",
    "    Converts each sentence from a list of words to a dictionary where the keys are id\n",
    "    :param formatted_corpus:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    formatted_corpus_dict = []\n",
    "    for sentence in formatted_corpus:\n",
    "        sentence_dict = {}\n",
    "        for word in sentence:\n",
    "            sentence_dict[word['ID']] = word\n",
    "        formatted_corpus_dict.append(sentence_dict)\n",
    "    return formatted_corpus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'ID': '0',\n",
       "  'FORM': 'ROOT',\n",
       "  'LEMMA': 'ROOT',\n",
       "  'UPOS': 'ROOT',\n",
       "  'XPOS': 'ROOT',\n",
       "  'FEATS': 'ROOT',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'ROOT',\n",
       "  'DEPS': '0',\n",
       "  'MISC': 'ROOT'},\n",
       " '1': {'ID': '1',\n",
       "  'FORM': 'Genom',\n",
       "  'LEMMA': 'genom',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'PP',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '2',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '2:case',\n",
       "  'MISC': '_'},\n",
       " '2': {'ID': '2',\n",
       "  'FORM': 'skattereformen',\n",
       "  'LEMMA': 'skattereform',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|DEF|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Def|Gender=Com|Number=Sing',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'obl',\n",
       "  'DEPS': '3:obl:genom',\n",
       "  'MISC': '_'},\n",
       " '3': {'ID': '3',\n",
       "  'FORM': 'införs',\n",
       "  'LEMMA': 'införa',\n",
       "  'UPOS': 'VERB',\n",
       "  'XPOS': 'VB|PRS|SFO',\n",
       "  'FEATS': 'Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Pass',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': '0:root',\n",
       "  'MISC': '_'},\n",
       " '4': {'ID': '4',\n",
       "  'FORM': 'individuell',\n",
       "  'LEMMA': 'individuell',\n",
       "  'UPOS': 'ADJ',\n",
       "  'XPOS': 'JJ|POS|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Degree=Pos|Gender=Com|Number=Sing',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'amod',\n",
       "  'DEPS': '5:amod',\n",
       "  'MISC': '_'},\n",
       " '5': {'ID': '5',\n",
       "  'FORM': 'beskattning',\n",
       "  'LEMMA': 'beskattning',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'nsubj:pass',\n",
       "  'DEPS': '3:nsubj:pass',\n",
       "  'MISC': '_'},\n",
       " '6': {'ID': '6',\n",
       "  'FORM': '(',\n",
       "  'LEMMA': '(',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'PAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '5:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '7': {'ID': '7',\n",
       "  'FORM': 'särbeskattning',\n",
       "  'LEMMA': 'särbeskattning',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'appos',\n",
       "  'DEPS': '5:appos',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '8': {'ID': '8',\n",
       "  'FORM': ')',\n",
       "  'LEMMA': ')',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'PAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '5:punct',\n",
       "  'MISC': '_'},\n",
       " '9': {'ID': '9',\n",
       "  'FORM': 'av',\n",
       "  'LEMMA': 'av',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'PP',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '10:case',\n",
       "  'MISC': '_'},\n",
       " '10': {'ID': '10',\n",
       "  'FORM': 'arbetsinkomster',\n",
       "  'LEMMA': 'arbetsinkomst',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|PLU|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Plur',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'nmod',\n",
       "  'DEPS': '5:nmod:av',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '11': {'ID': '11',\n",
       "  'FORM': '.',\n",
       "  'LEMMA': '.',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'MAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '3:punct',\n",
       "  'MISC': '_'}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_corpus_dict = convert_to_dict(formatted_corpus)\n",
    "formatted_corpus_dict[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the subject-verb pairs <a name='t2'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will extract the subject-verb pairs, where you will set the words in **lowercase**. In the second sentence of the corpus, this corresponds to `(beskattning, införs)`. You will call the function `extract_pairs(formatted_corpus_dict)` and and you will store the results in a `pairs_sv` variable. All the corpora in the universal dependencies format use the same **function names**: `nsubj` and `obj` for the subject and direct object.\n",
    "\n",
    "You can use the algorithm you want. However, here are some hints on the results:\n",
    "* You will extract all the subject-verb pairs in the corpus. In the extraction, just **check the function between two words**. Do not check if the **part of speech** is a verb or a noun in the pair. You will also ignore the possible **function suffixes** as in `nsubj:pass`, where `pass` means passive.\n",
    "* You will return the results as **Python's dictionaries**, where the key will be the pair and the value, the count, as for instance `{(beskattning, införs): 1}`. Be sure you understand the Python dictionaries and note that you can use tuples as keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the words in lowercase\n",
    "def lowercase(formatted_corpus_dict):\n",
    "    for sentence in formatted_corpus_dict:\n",
    "        for word in sentence.values():\n",
    "            word['FORM'] = word['FORM'].lower()\n",
    "    return formatted_corpus_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_corpus_dict = lowercase(formatted_corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'ID': '0',\n",
       "  'FORM': 'root',\n",
       "  'LEMMA': 'ROOT',\n",
       "  'UPOS': 'ROOT',\n",
       "  'XPOS': 'ROOT',\n",
       "  'FEATS': 'ROOT',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'ROOT',\n",
       "  'DEPS': '0',\n",
       "  'MISC': 'ROOT'},\n",
       " '1': {'ID': '1',\n",
       "  'FORM': 'genom',\n",
       "  'LEMMA': 'genom',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'PP',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '2',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '2:case',\n",
       "  'MISC': '_'},\n",
       " '2': {'ID': '2',\n",
       "  'FORM': 'skattereformen',\n",
       "  'LEMMA': 'skattereform',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|DEF|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Def|Gender=Com|Number=Sing',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'obl',\n",
       "  'DEPS': '3:obl:genom',\n",
       "  'MISC': '_'},\n",
       " '3': {'ID': '3',\n",
       "  'FORM': 'införs',\n",
       "  'LEMMA': 'införa',\n",
       "  'UPOS': 'VERB',\n",
       "  'XPOS': 'VB|PRS|SFO',\n",
       "  'FEATS': 'Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Pass',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': '0:root',\n",
       "  'MISC': '_'},\n",
       " '4': {'ID': '4',\n",
       "  'FORM': 'individuell',\n",
       "  'LEMMA': 'individuell',\n",
       "  'UPOS': 'ADJ',\n",
       "  'XPOS': 'JJ|POS|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Degree=Pos|Gender=Com|Number=Sing',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'amod',\n",
       "  'DEPS': '5:amod',\n",
       "  'MISC': '_'},\n",
       " '5': {'ID': '5',\n",
       "  'FORM': 'beskattning',\n",
       "  'LEMMA': 'beskattning',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'nsubj:pass',\n",
       "  'DEPS': '3:nsubj:pass',\n",
       "  'MISC': '_'},\n",
       " '6': {'ID': '6',\n",
       "  'FORM': '(',\n",
       "  'LEMMA': '(',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'PAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '5:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '7': {'ID': '7',\n",
       "  'FORM': 'särbeskattning',\n",
       "  'LEMMA': 'särbeskattning',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|SIN|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'appos',\n",
       "  'DEPS': '5:appos',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '8': {'ID': '8',\n",
       "  'FORM': ')',\n",
       "  'LEMMA': ')',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'PAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '5:punct',\n",
       "  'MISC': '_'},\n",
       " '9': {'ID': '9',\n",
       "  'FORM': 'av',\n",
       "  'LEMMA': 'av',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'PP',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '10:case',\n",
       "  'MISC': '_'},\n",
       " '10': {'ID': '10',\n",
       "  'FORM': 'arbetsinkomster',\n",
       "  'LEMMA': 'arbetsinkomst',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN|UTR|PLU|IND|NOM',\n",
       "  'FEATS': 'Case=Nom|Definite=Ind|Gender=Com|Number=Plur',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'nmod',\n",
       "  'DEPS': '5:nmod:av',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '11': {'ID': '11',\n",
       "  'FORM': '.',\n",
       "  'LEMMA': '.',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': 'MAD',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '3:punct',\n",
       "  'MISC': '_'}}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_corpus_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def extract_pairs(formatted_corpus_dict):\n",
    "    pairs_subjVerb = {}\n",
    "    #dict_subjVerb = {}\n",
    "    for sentence in formatted_corpus_dict:\n",
    "        #  extract the function with the method startswith('nsubj')\n",
    "        subjects = filter(lambda word: word['DEPREL'].startswith('nsubj'), \n",
    "                          list(sentence.values()) )\n",
    "        subjVerbs = map(lambda subj: (subj['FORM'], sentence[subj['HEAD']]['FORM']),\n",
    "                        subjects)\n",
    "        \n",
    "        # key is the pair and the value is the count\n",
    "        #dict_subjVerb = {}\n",
    "        for sv in subjVerbs:\n",
    "            #dict_subjVerb = {}\n",
    "            #dict_subjVerb[sv] = 1 + dict_subjVerb.get(sv, 0)\n",
    "            pairs_subjVerb[sv] = 1 + pairs_subjVerb.get(sv, 0)\n",
    "        #pairs_subjVerb.append(dict_subjVerb)\n",
    "            \n",
    "    return pairs_subjVerb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    }
   ],
   "source": [
    "pairs_sv = extract_pairs(formatted_corpus_dict)\n",
    "print(pairs_sv[('som', 'har')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will compute the **total number** of subject-verb pairs. You should find 6,083 pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6083"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([pairs_sv[pair] for pair in pairs_sv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the most frequent pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will sort your pairs by **frequency** and by **lexical order** of the pairs and store the five most frequent pairs in the `freq_pairs_sv` variable as in:\n",
    "```\n",
    "freq_pairs_sv = [(('som', 'har'), 45),\n",
    "\n",
    " ...]\n",
    " ````\n",
    "\n",
    "Here are the frequencies you should find:\n",
    "```\n",
    "45\n",
    "19\n",
    "19\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all the experiments, we will keep the `nbest` most frequent. In the first experiments, we set `nbest` to 3 first. We will set it to 5 in the last experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbest = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort first by frequency count, and then by alphabetical order\n",
    "sorted_pairs = sorted(pairs_sv, key=lambda x: (-pairs_sv[x], x))\n",
    "freq_pairs_sv = [(pair, pairs_sv[pair]) for pair in sorted_pairs][:nbest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('som', 'har'), 45), (('du', 'får'), 19), (('vi', 'har'), 19)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_pairs_sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the subject-verb-object triples <a name='t3'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now extract all the subject–verb–object triples of the corpus. The object function uses the `obj` code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def extract_triples(formatted_corpus_dict):\n",
    "    triples = {}\n",
    "    #dict_subjVerb = {}\n",
    "    for sentence in formatted_corpus_dict:\n",
    "        #  extract the function with the method startswith('nsubj')\n",
    "        subjects = list(filter(lambda word: word['DEPREL'].startswith('nsubj'), \n",
    "                               list(sentence.values())) )\n",
    "        subjVerbs = list(map(lambda subj: (subj, sentence[subj['HEAD']]), \n",
    "                             subjects))\n",
    "        objects = list(filter(lambda word: word['DEPREL'].startswith('obj'), \n",
    "                              list(sentence.values())) )\n",
    "        \n",
    "        # key is the pair and the value is the count\n",
    "        for obj in objects:\n",
    "            for sv in subjVerbs:\n",
    "                if sentence[obj['HEAD']]['ID'] == sv[1]['ID']:\n",
    "                    subject = sv[0]['FORM']\n",
    "                    verb = sv[1]['FORM']\n",
    "                    object = obj['FORM']\n",
    "                    \n",
    "                    triples[(subject, verb, object)] = 1 + triples.get((subject, \n",
    "                                                                        verb, \n",
    "                                                                        object), 0)\n",
    "            \n",
    "    return triples\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples_sv = extract_triples(formatted_corpus_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the **total number** of triples. You should find 2054 triples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2054"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([triples_sv[triple] for triple in triples_sv])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the most frequent triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will sort your triples by frequency and by lexical order of the pairs and store the three most frequent triples in the `freq_triples_sv` variable as in:\n",
    "```\n",
    "freq_triples_sv = [(('man', 'vänder', 'sig'), 14),\n",
    "\n",
    " ...]\n",
    " ````\n",
    "\n",
    "Here are the frequencies you should find:\n",
    "```\n",
    "14\n",
    "5\n",
    "3\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_triples = sorted(triples_sv, key=lambda x: (-triples_sv[x], x))\n",
    "freq_triples_sv = [(triple, triples_sv[triple]) for triple in sorted_triples][:nbest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('man', 'vänder', 'sig'), 14),\n",
       " (('det', 'rör', 'sig'), 5),\n",
       " (('man', 'söker', 'arbete'), 3)]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_triples_sv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilingual Corpora <a name='t4'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your program is working on Swedish, you will apply it to **all the other languages** in universal dependencies. The code below returns all the files from a folder with a **suffix**. Here we consider the **training files** only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir, suffix):\n",
    "    \"\"\"\n",
    "    Returns all the files in a folder ending with suffix\n",
    "    Recursive version\n",
    "    :param dir:\n",
    "    :param suffix:\n",
    "    :return: the list of file names\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    for file in os.listdir(dir):\n",
    "        path = dir + '/' + file\n",
    "        if os.path.isdir(path):\n",
    "            files += get_files(path, suffix)\n",
    "        elif os.path.isfile(path) and file.endswith(suffix):\n",
    "            files.append(path)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    }
   ],
   "source": [
    "files = get_files(ud_path, 'train.conllu')\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with the indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some corpora expand some tokens into **multiwords**. This is the case in French, Spanish, and German.\n",
    "        The table below shows examples of such expansions.\n",
    "        <table style=\"width:100%\">\n",
    "            <tr>\n",
    "                <th>French</th>\n",
    "                <th>Spanish</th>\n",
    "                <th>German</th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td><i>du</i>: de le\n",
    "                </td>\n",
    "                <td><i>del</i>: de el\n",
    "                </td>\n",
    "                <td><i>zur</i>: zu der\n",
    "                </td>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td><i>des</i>: de les\n",
    "                </td>\n",
    "                <td><i>vámonos</i>: vamos nos\n",
    "                </td>\n",
    "                <td><i>im</i>: in dem\n",
    "                </td>\n",
    "            </tr>\n",
    "        </table>\n",
    "        In the corpora, you have the original tokens as well as the multiwords as with <i>vámonos al mar</i>.\n",
    "        <pre>\n",
    "1-2 vámonos _\n",
    "1 vamos ir\n",
    "2 nos nosotros\n",
    "3-4 al _\n",
    "3 a a\n",
    "4 el el\n",
    "5 mar mar\n",
    "</pre>Read the **format** description for the details: [<a\n",
    "                href=\"http://universaldependencies.org/format.html\">CoNLL-U format</a>]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you represent the sentences as **lists**, the **item indices** are not reliable: In the format description,\n",
    "        the token at position 1 is <i>vamos</i> and not <i>vámonos</i>.\n",
    "        You have two ways to cope with this:\n",
    "1. Either **remove all the lines** that include a range in the `ID` field, or\n",
    "2. Encode the sentences as **dictionaries** (I felt this was preferable), where the keys are the `ID` numbers. This is what `convert_to_dict()` does. Here are the results for a sentence from the French CoNLL-U corpus:\n",
    "_Les iris du mâles sont jaunes toute l'année._ Note the `3-4` index and its expansion in `3`and `4`:\n",
    "```\n",
    "{'0': {'ID': '0',  'FORM': 'ROOT',  'LEMMA': 'ROOT',  'UPOS': 'ROOT',  'XPOS': 'ROOT',  'FEATS': 'ROOT',  'HEAD': '0',  'DEPREL': 'ROOT',  'DEPS': '0',  'MISC': 'ROOT'}, \n",
    "'1': {'ID': '1',  'FORM': 'Les',  'LEMMA': 'le',  'UPOS': 'DET',  'XPOS': '_',  'FEATS': 'Definite=Def|Gender=Masc|Number=Plur|PronType=Art',  'HEAD': '2',  'DEPREL': 'det',  'DEPS': '_',  'MISC': 'wordform=les'}, \n",
    "'2': {'ID': '2',  'FORM': 'iris',  'LEMMA': 'iris',  'UPOS': 'NOUN',  'XPOS': '_',  'FEATS': 'Gender=Masc|Number=Plur',  'HEAD': '7',  'DEPREL': 'nsubj',  'DEPS': '_',  'MISC': '_'}, \n",
    "'3-4': {'ID': '3-4',  'FORM': 'du',  'LEMMA': '_',  'UPOS': '_',  'XPOS': '_',  'FEATS': '_',  'HEAD': '_',  'DEPREL': '_',  'DEPS': '_',  'MISC': '_'}, \n",
    "'3': {'ID': '3',  'FORM': 'de',  'LEMMA': 'de',  'UPOS': 'ADP',  'XPOS': '_',  'FEATS': '_',  'HEAD': '5',  'DEPREL': 'case',  'DEPS': '_',  'MISC': '_'}, \n",
    "'4': {'ID': '4',  'FORM': 'le',  'LEMMA': 'le',  'UPOS': 'DET',  'XPOS': '_',  'FEATS': 'Definite=Def|Gender=Masc|Number=Sing|PronType=Art',  'HEAD': '5',  'DEPREL': 'det',  'DEPS': '_',  'MISC': '_'}, \n",
    "'5': {'ID': '5',  'FORM': 'mâles',  'LEMMA': 'mâle',  'UPOS': 'NOUN',  'XPOS': '_',  'FEATS': 'Gender=Masc|Number=Plur',  'HEAD': '2',  'DEPREL': 'nmod',  'DEPS': '_',  'MISC': '_'}, \n",
    "'6': {'ID': '6',  'FORM': 'sont',  'LEMMA': 'être',  'UPOS': 'AUX',  'XPOS': '_',  'FEATS': 'Mood=Ind|Number=Plur|Person=3|Tense=Pres|VerbForm=Fin',  'HEAD': '7',  'DEPREL': 'cop',  'DEPS': '_',  'MISC': '_'}, \n",
    "'7': {'ID': '7',  'FORM': 'jaunes',  'LEMMA': 'jaune',  'UPOS': 'ADJ',  'XPOS': '_',  'FEATS': 'Gender=Masc|Number=Plur',  'HEAD': '0',  'DEPREL': 'root',  'DEPS': '_',  'MISC': '_'}, \n",
    "'8': {'ID': '8',  'FORM': 'toute',  'LEMMA': 'tout',  'UPOS': 'ADJ',  'XPOS': '_',  'FEATS': 'Gender=Fem|Number=Sing',  'HEAD': '10',  'DEPREL': 'amod',  'DEPS': '_',  'MISC': '_'}, \n",
    "'9': {'ID': '9',  'FORM': \"l'\",  'LEMMA': 'le',  'UPOS': 'DET',  'XPOS': '_',  'FEATS': 'Definite=Def|Gender=Fem|Number=Sing|PronType=Art',  'HEAD': '10',  'DEPREL': 'det',  'DEPS': '_',  'MISC': 'SpaceAfter=No'}, \n",
    "'10': {'ID': '10',  'FORM': 'année',  'LEMMA': 'année',  'UPOS': 'NOUN',  'XPOS': '_',  'FEATS': 'Gender=Fem|Number=Sing',  'HEAD': '7',  'DEPREL': 'obl',  'DEPS': '_',  'MISC': 'SpaceAfter=No'}, \n",
    "'11': {'ID': '11',  'FORM': '.',  'LEMMA': '.',  'UPOS': 'PUNCT',  'XPOS': '_',  'FEATS': '_',  'HEAD': '7',  'DEPREL': 'punct',  'DEPS': '_',  'MISC': '_'}}\n",
    "```\n",
    "3. Some corpora have **sentence numbers**. You solve it by discarding lines starting with a `#`. This is already done in the CoNLL reader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the pairs and triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Write a function `extract_pairs_and_triples(formatted_corpus_dict, nbest)` that extracts the `nbest` most frequent **pairs and triples** of a given corpus and returns **two sorted lists of tuples**: `frequent_pairs` and `frequent_triples`. You will sort them by frequency and then by alphabetical order of the pair or triple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def extract_pairs_and_triples(formatted_corpus_dict, nbest):\n",
    "    # extracts the nbest most frequent pairs\n",
    "    pairs_sv = extract_pairs(formatted_corpus_dict)\n",
    "    sorted_pairs = sorted(pairs_sv, key=lambda x: (-pairs_sv[x], x))\n",
    "    frequent_pairs = [(pair, pairs_sv[pair]) for pair in sorted_pairs][:nbest]\n",
    "    \n",
    "    # extracts the nbest most frequent triples\n",
    "    triples_sv = extract_triples(formatted_corpus_dict)\n",
    "    sorted_triples = sorted(triples_sv, key=lambda x: (-triples_sv[x], x))\n",
    "    frequent_triples = [(triple, triples_sv[triple]) for triple in sorted_triples][:nbest]\n",
    "    \n",
    "    return frequent_pairs, frequent_triples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Run your extractor on all the corpora**. Note that some corpora have replaced the words by **underscores** as for one corpus in French. You need then to contact the provider to obtain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ud-treebanks-v2.6//UD_Afrikaans-AfriBooms/af_afribooms-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Ancient_Greek-Perseus/grc_perseus-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Ancient_Greek-PROIEL/grc_proiel-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Arabic-NYUAD/ar_nyuad-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Arabic-PADT/ar_padt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Armenian-ArmTDP/hy_armtdp-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Basque-BDT/eu_bdt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Belarusian-HSE/be_hse-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Bulgarian-BTB/bg_btb-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Buryat-BDT/bxr_bdt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Catalan-AnCora/ca_ancora-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Chinese-GSD/zh_gsd-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Chinese-GSDSimp/zh_gsdsimp-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Classical_Chinese-Kyoto/lzh_kyoto-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Coptic-Scriptorium/cop_scriptorium-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Croatian-SET/hr_set-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Czech-CAC/cs_cac-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Czech-CLTT/cs_cltt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Czech-FicTree/cs_fictree-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Czech-PDT/cs_pdt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Danish-DDT/da_ddt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Dutch-Alpino/nl_alpino-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Dutch-LassySmall/nl_lassysmall-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_English-ESL/en_esl-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_English-EWT/en_ewt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_English-GUM/en_gum-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_English-GUMReddit/en_gumreddit-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_English-LinES/en_lines-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_English-ParTUT/en_partut-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Estonian-EDT/et_edt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Estonian-EWT/et_ewt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Finnish-FTB/fi_ftb-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Finnish-TDT/fi_tdt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_French-FTB/fr_ftb-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_French-GSD/fr_gsd-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_French-ParTUT/fr_partut-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_French-Sequoia/fr_sequoia-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_French-Spoken/fr_spoken-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Galician-CTG/gl_ctg-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Galician-TreeGal/gl_treegal-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_German-GSD/de_gsd-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_German-HDT/de_hdt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Gothic-PROIEL/got_proiel-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Greek-GDT/el_gdt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Hebrew-HTB/he_htb-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Hindi-HDTB/hi_hdtb-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Hindi_English-HIENCS/qhe_hiencs-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Hungarian-Szeged/hu_szeged-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Indonesian-GSD/id_gsd-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Irish-IDT/ga_idt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Italian-ISDT/it_isdt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Italian-ParTUT/it_partut-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Italian-PoSTWITA/it_postwita-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Italian-TWITTIRO/it_twittiro-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Italian-VIT/it_vit-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Japanese-BCCWJ/ja_bccwj-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Japanese-GSD/ja_gsd-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Kazakh-KTB/kk_ktb-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Korean-GSD/ko_gsd-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Korean-Kaist/ko_kaist-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Kurmanji-MG/kmr_mg-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Latin-ITTB/la_ittb-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Latin-LLCT/la_llct-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Latin-Perseus/la_perseus-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Latin-PROIEL/la_proiel-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Latvian-LVTB/lv_lvtb-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Lithuanian-ALKSNIS/lt_alksnis-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Lithuanian-HSE/lt_hse-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Livvi-KKPP/olo_kkpp-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Maltese-MUDT/mt_mudt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Marathi-UFAL/mr_ufal-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Naija-NSC/pcm_nsc-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_North_Sami-Giella/sme_giella-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Norwegian-Bokmaal/no_bokmaal-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Norwegian-Nynorsk/no_nynorsk-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Norwegian-NynorskLIA/no_nynorsklia-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Old_Church_Slavonic-PROIEL/cu_proiel-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Old_French-SRCMF/fro_srcmf-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Old_Russian-RNC/orv_rnc-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Old_Russian-TOROT/orv_torot-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Persian-Seraji/fa_seraji-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Polish-LFG/pl_lfg-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Polish-PDB/pl_pdb-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Portuguese-Bosque/pt_bosque-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Portuguese-GSD/pt_gsd-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Romanian-Nonstandard/ro_nonstandard-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Romanian-RRT/ro_rrt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Russian-GSD/ru_gsd-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Russian-SynTagRus/ru_syntagrus-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Russian-Taiga/ru_taiga-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Sanskrit-Vedic/sa_vedic-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Scottish_Gaelic-ARCOSG/gd_arcosg-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Serbian-SET/sr_set-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Slovak-SNK/sk_snk-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Slovenian-SSJ/sl_ssj-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Slovenian-SST/sl_sst-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Spanish-AnCora/es_ancora-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Spanish-GSD/es_gsd-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Swedish-LinES/sv_lines-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Swedish-Talbanken/sv_talbanken-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Swedish_Sign_Language-SSLC/swl_sslc-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Tamil-TTB/ta_ttb-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Telugu-MTG/te_mtg-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Turkish-IMST/tr_imst-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Ukrainian-IU/uk_iu-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Upper_Sorbian-UFAL/hsb_ufal-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Urdu-UDTB/ur_udtb-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Uyghur-UDT/ug_udt-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Vietnamese-VTB/vi_vtb-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Welsh-CCG/cy_ccg-ud-train.conllu\n",
      "ud-treebanks-v2.6//UD_Wolof-WTB/wo_wtb-ud-train.conllu\n"
     ]
    }
   ],
   "source": [
    "# Write your code here\n",
    "\n",
    "files_dict = dict()\n",
    "for file in files:\n",
    "    sentences = read_sentences(file)\n",
    "    formatted_corpus = split_rows(sentences, column_names_u)\n",
    "    \n",
    "    # Encode the sentences as dictionaries and set in lowercase\n",
    "    formatted_corpus_dict = convert_to_dict(formatted_corpus)\n",
    "    #formatted_corpus_dict[1]\n",
    "    formatted_corpus_dict = lowercase(formatted_corpus_dict)\n",
    "    #formatted_corpus_dict[1]\n",
    "    \n",
    "    files_dict[file] = formatted_corpus_dict\n",
    "    print(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In your report, you will include the `nbest` most frequent pairs and triples you obtained in **three languages**. You may choose the ones you want.\n",
    "\n",
    "For the **checking script**, you will extract `nbest` triples in French, Russian, and English. You will rank these triples by frequency, and then by alphabetical order of the triple using `sorted()`. You will use the **French GSD** corpus, the **Russian SynTagRus** corpus, and the **English EWT** corpus. You will store these triples in the following variables:\n",
    "`freq_triples_fr`, `freq_triples_ru`, `freq_triples_en`. Each variable will contain a list of tuples: `(subject, verb, object), freq)`\n",
    "\n",
    "Here is what you should find:\n",
    "\n",
    "French\n",
    "```\n",
    "freq_triples_fr = [(('il', 'fait', 'partie'), 16),\n",
    "\n",
    " ...]\n",
    " ````\n",
    "\n",
    "And the frequencies:\n",
    "```\n",
    "16\n",
    "7\n",
    "7\n",
    "```\n",
    "\n",
    "Russian:\n",
    "```\n",
    "freq_triples_ru = [(('мы', 'имеем', 'дело'), 6),\n",
    "\n",
    " ...]\n",
    " ````\n",
    "\n",
    "And the frequencies:\n",
    "```\n",
    "6\n",
    "4\n",
    "4\n",
    "```\n",
    "\n",
    "English:\n",
    "```\n",
    "freq_triples_en = [(('you', 'have', 'questions'), 22),\n",
    "\n",
    " ...]\n",
    " ````\n",
    "\n",
    "And the frequencies:\n",
    "```\n",
    "22\n",
    "12\n",
    "7\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [path_fr, path_ru, path_en]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the French GSD corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'ID': '0',\n",
       "  'FORM': 'root',\n",
       "  'LEMMA': 'ROOT',\n",
       "  'UPOS': 'ROOT',\n",
       "  'XPOS': 'ROOT',\n",
       "  'FEATS': 'ROOT',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'ROOT',\n",
       "  'DEPS': '0',\n",
       "  'MISC': 'ROOT'},\n",
       " '1': {'ID': '1',\n",
       "  'FORM': \"l'\",\n",
       "  'LEMMA': 'le',\n",
       "  'UPOS': 'DET',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Definite=Def|Gender=Fem|Number=Sing|PronType=Art',\n",
       "  'HEAD': '2',\n",
       "  'DEPREL': 'det',\n",
       "  'DEPS': '_',\n",
       "  'MISC': \"SpaceAfter=No|wordform=l'\"},\n",
       " '2': {'ID': '2',\n",
       "  'FORM': 'œuvre',\n",
       "  'LEMMA': 'œuvre',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Gender=Fem|Number=Sing',\n",
       "  'HEAD': '4',\n",
       "  'DEPREL': 'nsubj:pass',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '3': {'ID': '3',\n",
       "  'FORM': 'est',\n",
       "  'LEMMA': 'être',\n",
       "  'UPOS': 'AUX',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin',\n",
       "  'HEAD': '4',\n",
       "  'DEPREL': 'aux:pass',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '4': {'ID': '4',\n",
       "  'FORM': 'située',\n",
       "  'LEMMA': 'situer',\n",
       "  'UPOS': 'VERB',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Gender=Fem|Number=Sing|Tense=Past|VerbForm=Part',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '5': {'ID': '5',\n",
       "  'FORM': 'dans',\n",
       "  'LEMMA': 'dans',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '6': {'ID': '6',\n",
       "  'FORM': 'la',\n",
       "  'LEMMA': 'le',\n",
       "  'UPOS': 'DET',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Definite=Def|Gender=Fem|Number=Sing|PronType=Art',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'det',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '7': {'ID': '7',\n",
       "  'FORM': 'galerie',\n",
       "  'LEMMA': 'galerie',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Gender=Fem|Number=Sing',\n",
       "  'HEAD': '4',\n",
       "  'DEPREL': 'obl:arg',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '8-9': {'ID': '8-9',\n",
       "  'FORM': 'des',\n",
       "  'LEMMA': '_',\n",
       "  'UPOS': '_',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '_',\n",
       "  'DEPREL': '_',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '8': {'ID': '8',\n",
       "  'FORM': 'de',\n",
       "  'LEMMA': 'de',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '9': {'ID': '9',\n",
       "  'FORM': 'les',\n",
       "  'LEMMA': 'le',\n",
       "  'UPOS': 'DET',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Definite=Def|Gender=Fem|Number=Plur|PronType=Art',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'det',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '10': {'ID': '10',\n",
       "  'FORM': 'batailles',\n",
       "  'LEMMA': 'bataille',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Gender=Fem|Number=Plur',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'nmod',\n",
       "  'DEPS': '_',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '11': {'ID': '11',\n",
       "  'FORM': ',',\n",
       "  'LEMMA': ',',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '14',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '12': {'ID': '12',\n",
       "  'FORM': 'dans',\n",
       "  'LEMMA': 'dans',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '14',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '13': {'ID': '13',\n",
       "  'FORM': 'le',\n",
       "  'LEMMA': 'le',\n",
       "  'UPOS': 'DET',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Definite=Def|Gender=Masc|Number=Sing|PronType=Art',\n",
       "  'HEAD': '14',\n",
       "  'DEPREL': 'det',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '14': {'ID': '14',\n",
       "  'FORM': 'château',\n",
       "  'LEMMA': 'château',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Gender=Masc|Number=Sing',\n",
       "  'HEAD': '4',\n",
       "  'DEPREL': 'obl:arg',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '15': {'ID': '15',\n",
       "  'FORM': 'de',\n",
       "  'LEMMA': 'de',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '16',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'},\n",
       " '16': {'ID': '16',\n",
       "  'FORM': 'versailles',\n",
       "  'LEMMA': 'Versailles',\n",
       "  'UPOS': 'PROPN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '14',\n",
       "  'DEPREL': 'nmod',\n",
       "  'DEPS': '_',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '17': {'ID': '17',\n",
       "  'FORM': '.',\n",
       "  'LEMMA': '.',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '4',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '_',\n",
       "  'MISC': '_'}}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "#formatted_corpus_dict = files_dict[files[0]]\n",
    "fr_sentences = read_sentences(files[0])\n",
    "fr_formatted_corpus = split_rows(fr_sentences, column_names_u)\n",
    "    \n",
    "# Encode the sentences as dictionaries and set in lowercase\n",
    "fr_formatted_corpus_dict = convert_to_dict(fr_formatted_corpus)\n",
    "#formatted_corpus_dict[1]\n",
    "formatted_corpus_dict = lowercase(fr_formatted_corpus_dict)\n",
    "formatted_corpus_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('il', 'fait', 'partie'), 16),\n",
       " (('elle', 'fait', 'partie'), 7),\n",
       " (('il', 'comptait', 'habitants'), 7)]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_pairs_fr, freq_triples_fr = extract_pairs_and_triples(formatted_corpus_dict, nbest)\n",
    "freq_triples_fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the Russian SynTagRus corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'ID': '0',\n",
       "  'FORM': 'root',\n",
       "  'LEMMA': 'ROOT',\n",
       "  'UPOS': 'ROOT',\n",
       "  'XPOS': 'ROOT',\n",
       "  'FEATS': 'ROOT',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'ROOT',\n",
       "  'DEPS': '0',\n",
       "  'MISC': 'ROOT'},\n",
       " '1': {'ID': '1',\n",
       "  'FORM': 'начальник',\n",
       "  'LEMMA': 'начальник',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'HEAD': '8',\n",
       "  'DEPREL': 'nsubj',\n",
       "  'DEPS': '8:nsubj',\n",
       "  'MISC': '_'},\n",
       " '2': {'ID': '2',\n",
       "  'FORM': 'областного',\n",
       "  'LEMMA': 'областной',\n",
       "  'UPOS': 'ADJ',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Case=Gen|Degree=Pos|Gender=Neut|Number=Sing',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'amod',\n",
       "  'DEPS': '3:amod',\n",
       "  'MISC': '_'},\n",
       " '3': {'ID': '3',\n",
       "  'FORM': 'управления',\n",
       "  'LEMMA': 'управление',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Inan|Case=Gen|Gender=Neut|Number=Sing',\n",
       "  'HEAD': '1',\n",
       "  'DEPREL': 'nmod',\n",
       "  'DEPS': '1:nmod',\n",
       "  'MISC': '_'},\n",
       " '4': {'ID': '4',\n",
       "  'FORM': 'связи',\n",
       "  'LEMMA': 'связь',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Inan|Case=Gen|Gender=Fem|Number=Sing',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'nmod',\n",
       "  'DEPS': '3:nmod',\n",
       "  'MISC': '_'},\n",
       " '5': {'ID': '5',\n",
       "  'FORM': 'семен',\n",
       "  'LEMMA': 'Семен',\n",
       "  'UPOS': 'PROPN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'HEAD': '1',\n",
       "  'DEPREL': 'appos',\n",
       "  'DEPS': '1:appos',\n",
       "  'MISC': '_'},\n",
       " '6': {'ID': '6',\n",
       "  'FORM': 'еремеевич',\n",
       "  'LEMMA': 'Еремеевич',\n",
       "  'UPOS': 'PROPN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'HEAD': '5',\n",
       "  'DEPREL': 'flat:name',\n",
       "  'DEPS': '5:flat:name',\n",
       "  'MISC': '_'},\n",
       " '7': {'ID': '7',\n",
       "  'FORM': 'был',\n",
       "  'LEMMA': 'быть',\n",
       "  'UPOS': 'AUX',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'HEAD': '8',\n",
       "  'DEPREL': 'cop',\n",
       "  'DEPS': '8:cop',\n",
       "  'MISC': '_'},\n",
       " '8': {'ID': '8',\n",
       "  'FORM': 'человек',\n",
       "  'LEMMA': 'человек',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Anim|Case=Nom|Gender=Masc|Number=Sing',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': '0:root',\n",
       "  'MISC': '_'},\n",
       " '9': {'ID': '9',\n",
       "  'FORM': 'простой',\n",
       "  'LEMMA': 'простой',\n",
       "  'UPOS': 'ADJ',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Case=Nom|Degree=Pos|Gender=Masc|Number=Sing',\n",
       "  'HEAD': '8',\n",
       "  'DEPREL': 'amod',\n",
       "  'DEPS': '8:amod',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '10': {'ID': '10',\n",
       "  'FORM': ',',\n",
       "  'LEMMA': ',',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '11',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '11:punct',\n",
       "  'MISC': '_'},\n",
       " '11': {'ID': '11',\n",
       "  'FORM': 'приходил',\n",
       "  'LEMMA': 'приходить',\n",
       "  'UPOS': 'VERB',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'HEAD': '8',\n",
       "  'DEPREL': 'conj',\n",
       "  'DEPS': '8:conj',\n",
       "  'MISC': '_'},\n",
       " '12': {'ID': '12',\n",
       "  'FORM': 'на',\n",
       "  'LEMMA': 'на',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '13',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '13:case',\n",
       "  'MISC': '_'},\n",
       " '13': {'ID': '13',\n",
       "  'FORM': 'работу',\n",
       "  'LEMMA': 'работа',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing',\n",
       "  'HEAD': '11',\n",
       "  'DEPREL': 'obl',\n",
       "  'DEPS': '11:obl',\n",
       "  'MISC': '_'},\n",
       " '14': {'ID': '14',\n",
       "  'FORM': 'всегда',\n",
       "  'LEMMA': 'всегда',\n",
       "  'UPOS': 'ADV',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Degree=Pos',\n",
       "  'HEAD': '11',\n",
       "  'DEPREL': 'advmod',\n",
       "  'DEPS': '11:advmod',\n",
       "  'MISC': '_'},\n",
       " '15': {'ID': '15',\n",
       "  'FORM': 'вовремя',\n",
       "  'LEMMA': 'вовремя',\n",
       "  'UPOS': 'ADV',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Degree=Pos',\n",
       "  'HEAD': '11',\n",
       "  'DEPREL': 'advmod',\n",
       "  'DEPS': '11:advmod',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '16': {'ID': '16',\n",
       "  'FORM': ',',\n",
       "  'LEMMA': ',',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '17',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '17:punct',\n",
       "  'MISC': '_'},\n",
       " '17': {'ID': '17',\n",
       "  'FORM': 'здоровался',\n",
       "  'LEMMA': 'здороваться',\n",
       "  'UPOS': 'VERB',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid',\n",
       "  'HEAD': '8',\n",
       "  'DEPREL': 'conj',\n",
       "  'DEPS': '8:conj',\n",
       "  'MISC': '_'},\n",
       " '18': {'ID': '18',\n",
       "  'FORM': 'с',\n",
       "  'LEMMA': 'с',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '19',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '19:case',\n",
       "  'MISC': '_'},\n",
       " '19': {'ID': '19',\n",
       "  'FORM': 'секретаршей',\n",
       "  'LEMMA': 'секретарша',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Anim|Case=Ins|Gender=Fem|Number=Sing',\n",
       "  'HEAD': '17',\n",
       "  'DEPREL': 'obl',\n",
       "  'DEPS': '17:obl',\n",
       "  'MISC': '_'},\n",
       " '20': {'ID': '20',\n",
       "  'FORM': 'за',\n",
       "  'LEMMA': 'за',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '21',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '21:case',\n",
       "  'MISC': '_'},\n",
       " '21': {'ID': '21',\n",
       "  'FORM': 'руку',\n",
       "  'LEMMA': 'рука',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing',\n",
       "  'HEAD': '17',\n",
       "  'DEPREL': 'obl',\n",
       "  'DEPS': '17:obl',\n",
       "  'MISC': '_'},\n",
       " '22': {'ID': '22',\n",
       "  'FORM': 'и',\n",
       "  'LEMMA': 'и',\n",
       "  'UPOS': 'CCONJ',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '25',\n",
       "  'DEPREL': 'cc',\n",
       "  'DEPS': '25:cc',\n",
       "  'MISC': '_'},\n",
       " '23': {'ID': '23',\n",
       "  'FORM': 'иногда',\n",
       "  'LEMMA': 'иногда',\n",
       "  'UPOS': 'ADV',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Degree=Pos',\n",
       "  'HEAD': '25',\n",
       "  'DEPREL': 'advmod',\n",
       "  'DEPS': '25:advmod',\n",
       "  'MISC': '_'},\n",
       " '24': {'ID': '24',\n",
       "  'FORM': 'даже',\n",
       "  'LEMMA': 'даже',\n",
       "  'UPOS': 'PART',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '25',\n",
       "  'DEPREL': 'advmod',\n",
       "  'DEPS': '25:advmod',\n",
       "  'MISC': '_'},\n",
       " '25': {'ID': '25',\n",
       "  'FORM': 'писал',\n",
       "  'LEMMA': 'писать',\n",
       "  'UPOS': 'VERB',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Aspect=Imp|Gender=Masc|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Act',\n",
       "  'HEAD': '8',\n",
       "  'DEPREL': 'conj',\n",
       "  'DEPS': '8:conj',\n",
       "  'MISC': '_'},\n",
       " '26': {'ID': '26',\n",
       "  'FORM': 'в',\n",
       "  'LEMMA': 'в',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '27',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '27:case',\n",
       "  'MISC': '_'},\n",
       " '27': {'ID': '27',\n",
       "  'FORM': 'стенгазету',\n",
       "  'LEMMA': 'стенгазета',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Inan|Case=Acc|Gender=Fem|Number=Sing',\n",
       "  'HEAD': '25',\n",
       "  'DEPREL': 'obl',\n",
       "  'DEPS': '25:obl',\n",
       "  'MISC': '_'},\n",
       " '28': {'ID': '28',\n",
       "  'FORM': 'заметки',\n",
       "  'LEMMA': 'заметка',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Inan|Case=Acc|Gender=Fem|Number=Plur',\n",
       "  'HEAD': '25',\n",
       "  'DEPREL': 'obj',\n",
       "  'DEPS': '25:obj',\n",
       "  'MISC': '_'},\n",
       " '29': {'ID': '29',\n",
       "  'FORM': 'под',\n",
       "  'LEMMA': 'под',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '30',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '30:case',\n",
       "  'MISC': '_'},\n",
       " '30': {'ID': '30',\n",
       "  'FORM': 'псевдонимом',\n",
       "  'LEMMA': 'псевдоним',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Inan|Case=Ins|Gender=Masc|Number=Sing',\n",
       "  'HEAD': '25',\n",
       "  'DEPREL': 'obl',\n",
       "  'DEPS': '25:obl',\n",
       "  'MISC': '_'},\n",
       " '31': {'ID': '31',\n",
       "  'FORM': '\"',\n",
       "  'LEMMA': '\"',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '32',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '32:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '32': {'ID': '32',\n",
       "  'FORM': 'муха',\n",
       "  'LEMMA': 'муха',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': 'Animacy=Anim|Case=Nom|Gender=Fem|Number=Sing',\n",
       "  'HEAD': '30',\n",
       "  'DEPREL': 'nmod',\n",
       "  'DEPS': '30:nmod',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '33': {'ID': '33',\n",
       "  'FORM': '\"',\n",
       "  'LEMMA': '\"',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '32',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '32:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '34': {'ID': '34',\n",
       "  'FORM': '.',\n",
       "  'LEMMA': '.',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': '_',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '8',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '8:punct',\n",
       "  'MISC': '_'}}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "ru_sentences = read_sentences(files[1])\n",
    "ru_formatted_corpus = split_rows(ru_sentences, column_names_u)\n",
    "    \n",
    "# Encode the sentences as dictionaries and set in lowercase\n",
    "ru_formatted_corpus_dict = convert_to_dict(ru_formatted_corpus)\n",
    "#formatted_corpus_dict[1]\n",
    "formatted_corpus_dict = lowercase(ru_formatted_corpus_dict)\n",
    "formatted_corpus_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('мы', 'имеем', 'дело'), 6),\n",
       " (('мы', 'имеем', 'что'), 4),\n",
       " (('мы', 'сделаем', 'все'), 4)]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_pairs_ru, freq_triples_ru = extract_pairs_and_triples(formatted_corpus_dict, nbest)\n",
    "freq_triples_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the English EWT corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': {'ID': '0',\n",
       "  'FORM': 'root',\n",
       "  'LEMMA': 'ROOT',\n",
       "  'UPOS': 'ROOT',\n",
       "  'XPOS': 'ROOT',\n",
       "  'FEATS': 'ROOT',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'ROOT',\n",
       "  'DEPS': '0',\n",
       "  'MISC': 'ROOT'},\n",
       " '1': {'ID': '1',\n",
       "  'FORM': '[',\n",
       "  'LEMMA': '[',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': '-LRB-',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '10:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '2': {'ID': '2',\n",
       "  'FORM': 'this',\n",
       "  'LEMMA': 'this',\n",
       "  'UPOS': 'DET',\n",
       "  'XPOS': 'DT',\n",
       "  'FEATS': 'Number=Sing|PronType=Dem',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'det',\n",
       "  'DEPS': '3:det',\n",
       "  'MISC': '_'},\n",
       " '3': {'ID': '3',\n",
       "  'FORM': 'killing',\n",
       "  'LEMMA': 'killing',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN',\n",
       "  'FEATS': 'Number=Sing',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'nsubj',\n",
       "  'DEPS': '10:nsubj',\n",
       "  'MISC': '_'},\n",
       " '4': {'ID': '4',\n",
       "  'FORM': 'of',\n",
       "  'LEMMA': 'of',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'IN',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '7:case',\n",
       "  'MISC': '_'},\n",
       " '5': {'ID': '5',\n",
       "  'FORM': 'a',\n",
       "  'LEMMA': 'a',\n",
       "  'UPOS': 'DET',\n",
       "  'XPOS': 'DT',\n",
       "  'FEATS': 'Definite=Ind|PronType=Art',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'det',\n",
       "  'DEPS': '7:det',\n",
       "  'MISC': '_'},\n",
       " '6': {'ID': '6',\n",
       "  'FORM': 'respected',\n",
       "  'LEMMA': 'respected',\n",
       "  'UPOS': 'ADJ',\n",
       "  'XPOS': 'JJ',\n",
       "  'FEATS': 'Degree=Pos',\n",
       "  'HEAD': '7',\n",
       "  'DEPREL': 'amod',\n",
       "  'DEPS': '7:amod',\n",
       "  'MISC': '_'},\n",
       " '7': {'ID': '7',\n",
       "  'FORM': 'cleric',\n",
       "  'LEMMA': 'cleric',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN',\n",
       "  'FEATS': 'Number=Sing',\n",
       "  'HEAD': '3',\n",
       "  'DEPREL': 'nmod',\n",
       "  'DEPS': '3:nmod:of',\n",
       "  'MISC': '_'},\n",
       " '8': {'ID': '8',\n",
       "  'FORM': 'will',\n",
       "  'LEMMA': 'will',\n",
       "  'UPOS': 'AUX',\n",
       "  'XPOS': 'MD',\n",
       "  'FEATS': 'VerbForm=Fin',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'aux',\n",
       "  'DEPS': '10:aux',\n",
       "  'MISC': '_'},\n",
       " '9': {'ID': '9',\n",
       "  'FORM': 'be',\n",
       "  'LEMMA': 'be',\n",
       "  'UPOS': 'AUX',\n",
       "  'XPOS': 'VB',\n",
       "  'FEATS': 'VerbForm=Inf',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'aux',\n",
       "  'DEPS': '10:aux',\n",
       "  'MISC': '_'},\n",
       " '10': {'ID': '10',\n",
       "  'FORM': 'causing',\n",
       "  'LEMMA': 'cause',\n",
       "  'UPOS': 'VERB',\n",
       "  'XPOS': 'VBG',\n",
       "  'FEATS': 'VerbForm=Ger',\n",
       "  'HEAD': '0',\n",
       "  'DEPREL': 'root',\n",
       "  'DEPS': '0:root',\n",
       "  'MISC': '_'},\n",
       " '11': {'ID': '11',\n",
       "  'FORM': 'us',\n",
       "  'LEMMA': 'we',\n",
       "  'UPOS': 'PRON',\n",
       "  'XPOS': 'PRP',\n",
       "  'FEATS': 'Case=Acc|Number=Plur|Person=1|PronType=Prs',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'iobj',\n",
       "  'DEPS': '10:iobj',\n",
       "  'MISC': '_'},\n",
       " '12': {'ID': '12',\n",
       "  'FORM': 'trouble',\n",
       "  'LEMMA': 'trouble',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NN',\n",
       "  'FEATS': 'Number=Sing',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'obj',\n",
       "  'DEPS': '10:obj',\n",
       "  'MISC': '_'},\n",
       " '13': {'ID': '13',\n",
       "  'FORM': 'for',\n",
       "  'LEMMA': 'for',\n",
       "  'UPOS': 'ADP',\n",
       "  'XPOS': 'IN',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '14',\n",
       "  'DEPREL': 'case',\n",
       "  'DEPS': '14:case',\n",
       "  'MISC': '_'},\n",
       " '14': {'ID': '14',\n",
       "  'FORM': 'years',\n",
       "  'LEMMA': 'year',\n",
       "  'UPOS': 'NOUN',\n",
       "  'XPOS': 'NNS',\n",
       "  'FEATS': 'Number=Plur',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'obl',\n",
       "  'DEPS': '10:obl:for',\n",
       "  'MISC': '_'},\n",
       " '15': {'ID': '15',\n",
       "  'FORM': 'to',\n",
       "  'LEMMA': 'to',\n",
       "  'UPOS': 'PART',\n",
       "  'XPOS': 'TO',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '16',\n",
       "  'DEPREL': 'mark',\n",
       "  'DEPS': '16:mark',\n",
       "  'MISC': '_'},\n",
       " '16': {'ID': '16',\n",
       "  'FORM': 'come',\n",
       "  'LEMMA': 'come',\n",
       "  'UPOS': 'VERB',\n",
       "  'XPOS': 'VB',\n",
       "  'FEATS': 'VerbForm=Inf',\n",
       "  'HEAD': '14',\n",
       "  'DEPREL': 'acl',\n",
       "  'DEPS': '14:acl:to',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '17': {'ID': '17',\n",
       "  'FORM': '.',\n",
       "  'LEMMA': '.',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': '.',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '10:punct',\n",
       "  'MISC': 'SpaceAfter=No'},\n",
       " '18': {'ID': '18',\n",
       "  'FORM': ']',\n",
       "  'LEMMA': ']',\n",
       "  'UPOS': 'PUNCT',\n",
       "  'XPOS': '-RRB-',\n",
       "  'FEATS': '_',\n",
       "  'HEAD': '10',\n",
       "  'DEPREL': 'punct',\n",
       "  'DEPS': '10:punct',\n",
       "  'MISC': '_'}}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "en_sentences = read_sentences(files[2])\n",
    "en_formatted_corpus = split_rows(en_sentences, column_names_u)\n",
    "\n",
    "# Encode the sentences as dictionaries and set in lowercase\n",
    "en_formatted_corpus_dict = convert_to_dict(en_formatted_corpus)\n",
    "#formatted_corpus_dict[1]\n",
    "formatted_corpus_dict = lowercase(en_formatted_corpus_dict)\n",
    "formatted_corpus_dict[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('you', 'have', 'questions'), 22),\n",
       " (('you', 'think', 'what'), 12),\n",
       " (('i', 'do', 'what'), 7)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_pairs_en, freq_triples_en = extract_pairs_and_triples(formatted_corpus_dict, nbest)\n",
    "freq_triples_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolving the entities <a name='t5'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now extract the **relations** involving named entities, that is where both the subject and the object are **proper nouns**. \n",
    "\n",
    "- Write an `extract_entity_triples(formatted_corpus_dict)` that will process the corpus and return a **list** of `(subject, verb, object)` triples. You will leave the case as it is in the form, for instance _United States_ and not _united states_.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "def extract_entity_triples(formatted_corpus_dict):\n",
    "    triples_propn = {}\n",
    "    #dict_subjVerb = {}\n",
    "    for sentence in formatted_corpus_dict:\n",
    "        #  extract the function with the method startswith('nsubj')\n",
    "        subjects = list(filter(lambda word: word['DEPREL'].startswith('nsubj')\n",
    "                               and word['UPOS'] == 'PROPN', \n",
    "                               list(sentence.values())) )\n",
    "        #subjects_propn = list(filter(lambda sub: sub['UPOS'] == 'PROPN'), subjects)\n",
    "        subjVerbs = list(map(lambda subj: (subj, sentence[subj['HEAD']]), \n",
    "                             subjects))\n",
    "        objects = list(filter(lambda word: word['DEPREL'].startswith('obj')\n",
    "                              and word['UPOS'] == 'PROPN', \n",
    "                              list(sentence.values())) )\n",
    "        #objects_propn = list(filter(lambda obj: obj['UPOS'] == 'PROPN'), objects)\n",
    "        \n",
    "        # key is the pair and the value is the count\n",
    "        for obj in objects:\n",
    "            for sv in subjVerbs:\n",
    "                if sentence[obj['HEAD']]['ID'] == sv[1]['ID']:\n",
    "                    subject = sv[0]['FORM']\n",
    "                    verb = sv[1]['FORM']\n",
    "                    object = obj['FORM']\n",
    "                    \n",
    "                    triples_propn[(subject, verb, object)] = 1 + triples_propn.get((subject, \n",
    "                                                                                    verb, \n",
    "                                                                                   object), 0)\n",
    "            \n",
    "    return triples_propn\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#en_sentences = read_sentences(files[2])\n",
    "en_sentences = read_sentences(path_en)\n",
    "en_formatted_corpus = split_rows(en_sentences, column_names_u)\n",
    "\n",
    "#Encode the sentences as dictionaries and set in lowercase\n",
    "en_formatted_corpus_dict = convert_to_dict(en_formatted_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "triples_propn_en = extract_entity_triples(en_formatted_corpus_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sum([triples_propn_en[triple] for triple in triples_propn_en])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sorted_triples_propn = sorted(triples_propn_en, key=lambda x: (-triples_propn_en[x], x))\n",
    "frequent_triples_propn_en = [(triple, triples_propn_en[triple]) \n",
    "                             for triple in sorted_triples_propn][:nbest]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "frequent_triples_propn_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will run the `extract_entity_triples()` function on the **English EWT** corpus. You will store the list in the `entity_relation_en` variable and you will sort it with `sorted()`. You will keep the **five** first triples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbest = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two first triples are:\n",
    "```\n",
    "[('Baba', 'remember', 'George'),\n",
    " ('Beschta', 'told', 'Planet'),\n",
    "...]\n",
    " ```\n",
    "Note that this time, we keep the **original case** and the triples are in the **alphabetical order**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write your code here\n",
    "#en_sentences = read_sentences(files[2])\n",
    "en_sentences = read_sentences(path_en)\n",
    "en_formatted_corpus = split_rows(en_sentences, column_names_u)\n",
    "\n",
    "# Encode the sentences as dictionaries and set in lowercase\n",
    "en_formatted_corpus_dict = convert_to_dict(en_formatted_corpus)\n",
    "\n",
    "# extract the relations involving named entities, \n",
    "# where both the subject and the object are proper nouns.\n",
    "entity_relation_en = extract_entity_triples(en_formatted_corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Baba', 'remember', 'George'),\n",
       " ('Beschta', 'told', 'Planet'),\n",
       " ('Boi', 'beat', 'Lopez'),\n",
       " ('Bush', 'mentioned', 'Arabia'),\n",
       " ('Bush', 'mentioned', 'Osama')]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_relation_en = sorted(entity_relation_en)[:nbest]\n",
    "entity_relation_en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional exercise: Extracting the chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting only the **headword** of the subject and object is often incomplete and uninformative. You can extract all the chunk instead. As an optional exercise, you can try a **baseline technique** and extract adjacent proper nouns. You may also want to apply the chunker of the **4th assignment** to the corpus to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional exercise: Mapping the entities <a name='t6'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the chunker assignment, you may also want to complement your assignment with a **entity solver** that will link the entities to **wikidata**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading <a name='t7'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the article: _PRISMATIC: Inducing Knowledge from a Large Scale Lexicalized Relation Resource_ by Fan and al. (2010) [<a href=\"http://www.aclweb.org/anthology/W/W10/W10-0915.pdf\">pdf</a>] and write in a few sentences how it relates to your work in this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission <a name='t8'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you have written all the code and run all the cells, fill in your ID and as well as the name of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "STIL_ID = [\"hi8826mo-s\"] # Write your stil ids as a list\n",
    "CURRENT_NOTEBOOK_PATH = os.path.join(os.getcwd(), \n",
    "                                     \"5-Triples_HichamMohamad.ipynb\") # Write the name of your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submission code will send your answer. It consists of the pairs and triples in four languages, as well as the triples with named entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"freq_triples_sv\": [[[\"man\", \"v\\\\u00e4nder\", \"sig\"], 14], [[\"det\", \"r\\\\u00f6r\", \"sig\"], 5], [[\"man\", \"s\\\\u00f6ker\", \"arbete\"], 3]], \"freq_triples_fr\": [[[\"il\", \"fait\", \"partie\"], 16], [[\"elle\", \"fait\", \"partie\"], 7], [[\"il\", \"comptait\", \"habitants\"], 7]], \"freq_triples_ru\": [[[\"\\\\u043c\\\\u044b\", \"\\\\u0438\\\\u043c\\\\u0435\\\\u0435\\\\u043c\", \"\\\\u0434\\\\u0435\\\\u043b\\\\u043e\"], 6], [[\"\\\\u043c\\\\u044b\", \"\\\\u0438\\\\u043c\\\\u0435\\\\u0435\\\\u043c\", \"\\\\u0447\\\\u0442\\\\u043e\"], 4], [[\"\\\\u043c\\\\u044b\", \"\\\\u0441\\\\u0434\\\\u0435\\\\u043b\\\\u0430\\\\u0435\\\\u043c\", \"\\\\u0432\\\\u0441\\\\u0435\"], 4]], \"freq_triples_en\": [[[\"you\", \"have\", \"questions\"], 22], [[\"you\", \"think\", \"what\"], 12], [[\"i\", \"do\", \"what\"], 7]], \"entity_relation_en\": [[\"Baba\", \"remember\", \"George\"], [\"Beschta\", \"told\", \"Planet\"], [\"Boi\", \"beat\", \"Lopez\"], [\"Bush\", \"mentioned\", \"Arabia\"], [\"Bush\", \"mentioned\", \"Osama\"]]}'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "ANSWER = json.dumps({'freq_triples_sv': freq_triples_sv,\n",
    "                     'freq_triples_fr': freq_triples_fr,\n",
    "                     'freq_triples_ru': freq_triples_ru,\n",
    "                     'freq_triples_en': freq_triples_en,\n",
    "                     'entity_relation_en': entity_relation_en\n",
    "                    })\n",
    "ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the moment of truth:\n",
    "1. Save your notebook and\n",
    "2. Run the cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_NOTEBOOK_PATH = CURRENT_NOTEBOOK_PATH + \".submission.bz2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "ASSIGNMENT = 5\n",
    "API_KEY = \"f581ba347babfea0b8f2c74a3a6776a7\"\n",
    "\n",
    "# Copy and compress current notebook\n",
    "with bz2.open(SUBMISSION_NOTEBOOK_PATH, mode=\"wb\") as fout:\n",
    "    with open(CURRENT_NOTEBOOK_PATH, \"rb\") as fin:\n",
    "        fout.write(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'msg': None,\n",
       " 'status': 'correct',\n",
       " 'signature': '33ed85cff50228606e318e9055921389dc13e7572dc1638c9f00774ce4e9588efc0dc5adef733ff63ff85c23cfea4158294ad38e1de913a89342ed0bb263aaff',\n",
       " 'submission_id': '6b987640-656a-4de7-b3a0-c9afa29f4dca'}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "res = requests.post(\"https://vilde.cs.lth.se/edan20checker/submit\", \n",
    "                    files={\"notebook_file\": open(SUBMISSION_NOTEBOOK_PATH, \"rb\")}, \n",
    "                    data={\n",
    "                        \"stil_id\": STIL_ID,\n",
    "                        \"assignment\": ASSIGNMENT,\n",
    "                        \"answer\": ANSWER,\n",
    "                        \"api_key\": API_KEY,\n",
    "                    },\n",
    "               verify=True)\n",
    "\n",
    "# from IPython.display import display, JSON\n",
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
